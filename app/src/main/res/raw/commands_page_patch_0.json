[{"id": 18516,"commandid" : 2451,"title": "Name","page":"<br><br>clang - the Clang C and Objective-C compiler"},{"id": 18517,"commandid" : 2451,"title":"Synopsis","page":"<br><br><b>clang</b> [<b>-c</b>|<b>-S</b>|<b>-E</b>] <b>-std=</b>standard <b>-g</b> [<b>-O0</b>|<b>-O1</b>|<b>-O2</b>|<b>-Os</b>|<b>-O3</b>|<b>-O4</b>] <b>-W</b>warnings... <b>-pedantic -I</b>dir... <b>-L</b>dir... <b>-D</b>macro[=defn] <b>-f</b>feature-option... <b>-m</b>machine-option... <b>-o</b> output-file input-filenames"},{"id": 18518,"commandid" : 2451,"title": "Description","page":"<br><br><b>clang</b> is a C and Objective-C compiler which encompasses preprocessing, parsing, optimization, code generation, assembly, and linking. Depending on which high-level mode setting is passed, Clang will stop before doing a full link. While Clang is highly integrated, it is important to understand the stages of compilation, to understand how to invoke it. These stages are: Driver The <b>clang</b> executable is actually a small driver which controls the overall execution of other tools such as the compiler, assembler and linker. Typically you do not need to interact with the driver, but you transparently use it to run the other tools.Preprocessing This stage handles tokenization of the input source file, macro expansion, #include expansion and handling of other preprocessor directives. The output of this stage is typically called a .i (for C) or .mi (for Objective-C) file.Parsing and Semantic Analysis This stage parses the input file, translating preprocessor tokens into a parse tree. Once in the form of a parser tree, it applies semantic analysis to compute types for expressions as well and determine whether the code is well formed. This stage is responsible for generating most of the compiler warnings as well as parse errors. The output of this stage is an Abstract Syntax Tree ( AST ).Code Generation and Optimization This stage translates an AST into low-level intermediate code (known as LLVM IR ) and ultimately to machine code. This phase is responsible for optimizing the generated code and handling target-specfic code generation. The output of this stage is typically called a .s file or assembly file. <p>Clang also supports the use of an integrated assembler, in which the code generator produces object files directly. This avoids the overhead of generating the .s file and of calling the target assembler. </p>Assembler This stage runs the target assembler to translate the output of the compiler into a target object file. The output of this stage is typically called a .o file or object file.Linker This stage runs the target linker to merge multiple object files into an executable or dynamic library. The output of this stage is typically called an a.out, .dylib or .so file.The <br><br><b>Clang Static Analyzer</b><br><br>The Clang Static Analyzer is a tool that scans source code to try to find bugs though code analysis. This tool uses many parts of Clang and is built into the same driver. "},{"id": 18519,"commandid" : 2451,"title": "Options","page": " <br><br><b>Stage Selection Options</b> -E <br><br>Run the preprocessor stage.-fsyntax-only Run the preprocessor, parser and type checking stages.-S <br><br>Run the previous stages as well as LLVM generation and optimization stages and target-specific code generation, producing an assembly file.<br><br><b>-c</b><br><br>Run all of the above, plus the assembler, generating a target .o object file.no stage selection option If no stage selection option is specified, all stages above are run, and the linker is run to combine the results into an executable or shared library.--analyze Run the Clang Static Analyzer. <br><br><b>Language Selection and Mode Options</b> -x Treat subsequent input files as having type language.-std=Specify the language standard to compile for.-ansi Same as <b>-std=c89</b>.-ObjC++ Treat source input files as Objective-C ++ inputs.-ObjC Treat source input files as Objective-C inputs.-trigraphs Enable trigraphs.-ffreestanding Indicate that the file should be compiled for a freestanding, not a hosted, environment.-fno-builtin Disable special handling and optimizations of builtin functions like strlen and malloc.-fmath-errno Indicate that math functions should be treated as updating errno.-fpascal-strings Enable support for Pascal-style strings with pfoo.-fms-extensions Enable support for Microsoft extensions.-fborland-extensions Enable support for Borland extensions.-fwritable-strings Make all string literals default to writable. This disables uniquing of strings and other optimizations.-flax-vector-conversions Allow loose type checking rules for implicit vector conversions.-fblocks Enable the Blocks language feature.-fobjc-gc-only Indicate that Objective-C code should be compiled in GC-only mode, which only works when Objective-C Garbage Collection is enabled.-fobjc-gc Indicate that Objective-C code should be compiled in hybrid-GC mode, which works with both GC and non-GC mode. <br><br><b>Target Selection Options</b> -arch Specify the architecture to build for.-mmacosx-version-min=When building for Mac OS/X , specify the minimum version supported by your application.-miphoneos-version-min When building for iPhone OS , specify the minimum version supported by your application.-march=Specify that Clang should generate code for a specific processor family member and later. For example, if you specify -march=i486, the compiler is allowed to generate instructions that are valid on i486 and later processors, but which may not exist on earlier ones. <br><br><b>Code Generation Options</b> -O0 -O1 -O2 -Os -O3 -O4 Specify which optimization level to use. <b>-O0</b> means no optimization: this level compiles the fastest and generates the most debuggable code. <b>-O2</b> is a moderate level of optimization which enables most optimizations. <b>-Os</b> is like <b>-O2</b> with extra optimizations to reduce code size. <b>-O3</b> is like <b>-O2</b>, except that it enables optimizations that take longer to perform or that may generate larger code (in an attempt to make the program run faster). On supported platforms, <b>-O4</b> enables link-time optimization; object files are stored in the LLVM bitcode file format and whole program optimization is done at link time. <b>-O1</b> is somewhere between <b>-O0</b> and <b>-O2</b>.-g <br><br>Generate debug information. Note that Clang debug information works best at <b>-O0</b>. At higher optimization levels, only line number information is currently available.-fexceptions Enable generation of unwind information, this allows exceptions to be thrown through Clang compiled stack frames. This is on by default in x86-64.-ftrapv Generate code to catch integer overflow errors. Signed integer overflow is undefined in C, with this flag, extra code is generated to detect this and abort when it happens.-fvisibility This flag sets the default visibility level.-fcommon This flag specifies that variables without initializers get common linkage. It can be disabled with <b>-fno-common</b>.-flto -emit-llvm Generate output files in LLVM formats, suitable for link time optimization. When used with <b>-S</b> this generates LLVM intermediate language assembly files, otherwise this generates LLVM bitcode format object files (which may be passed to the linker depending on the stage selection options). <br><br><b>Driver Options</b> -### Print the commands to run for this compilation.--help Display available options.-Qunused-arguments Dont emit warning for unused driver arguments.-Wa,argsPass the comma separated arguments in args to the assembler.-Wl,argsPass the comma separated arguments in args to the linker.-Wp,argsPass the comma separated arguments in args to the preprocessor.-Xanalyzer Pass arg to the static analyzer.-Xassembler Pass arg to the assembler.-Xclang Pass arg to the clang compiler frontend.-Xlinker Pass arg to the linker.-mllvm Pass arg to the LLVM backend.-Xpreprocessor Pass arg to the preprocessor.-o Write output to file.-print-file-name=Print the full library path of file.-print-libgcc-file-name Print the library path for libgcc.a.-print-prog-name=Print the full program path of name.-print-search-dirs Print the paths used for finding libraries and programs.-save-temps Save intermediate compilation results.-integrated-as -no-integrated-as Used to enable and disable, respectively, the use of the integrated assembler. Whether the integrated assembler is on by default is target dependent.-time Time individual commands.-ftime-report Print timing summary of each stage of compilation.-v <br><br>Show commands to run and use verbose output. <br><br><b>Diagnostics Options</b> -fshow-column -fshow-source-location -fcaret-diagnostics -fdiagnostics-fixit-info -fdiagnostics-parseable-fixits -fdiagnostics-print-source-range-info -fprint-source-range-info -fdiagnostics-show-option -fmessage-length These options control how Clang prints out information about diagnostics (errors and warnings). Please see the Clang Users Manual for more information. <br><br><b>Preprocessor Options</b> -Dmacroname=valueAdds an implicit #define into the predefines buffer which is read before the source file is preprocessed.-UmacronameAdds an implicit #undef into the predefines buffer which is read before the source file is preprocessed.-include Adds an implicit #include into the predefines buffer which is read before the source file is preprocessed.-IdirectoryAdd the specified directory to the search path for include files.-FdirectoryAdd the specified directory to the search path for framework include files.-nostdinc Do not search the standard system directories for include files.-nobuiltininc Do not search clangs builtin directory for include files. "},{"id": 18520,"commandid" : 2451,"title": "Environment","page": " <br><br><b>TMPDIR</b> , <b>TEMP</b> , <b>TMP</b> These environment variables are checked, in order, for the location to write temporary files used during the compilation process.CPATH If this environment variable is present, it is treated as a delimited list of paths to be added to the default system include path list. The delimiter is the platform dependent delimitor, as used in the PATH environment variable. <p>Empty components in the environment variable are ignored. </p>C_INCLUDE_PATH, OBJC_INCLUDE_PATH , CPLUS_INCLUDE_PATH , OBJCPLUS_INCLUDE_PATH These environment variables specify additional paths, as for CPATH , which are only used when processing the appropriate language.MACOSX_DEPLOYMENT_TARGET If -mmacosx-version-min is unspecified, the default deployment target is read from this environment variable. This option only affects darwin targets. "},{"id": 18521,"commandid" : 2451,"title": "Bugs","page": " <br><br>To report bugs, please visit &lt;&gt;. Most bug reports should include preprocessed source files (use the <b>-E</b> option) and the full output of the compiler, along with information to reproduce."},{"id": 18522,"commandid" : 2451,"title": "See Also","page": " <a href=as>as</a>(1), <a href=ld>ld</a>(1)"},{"id": 18523,"commandid" : 2451,"title": "Author","page": " <br><br>Maintained by the Clang / LLVM Team"},{"id": 18524,"commandid" : 2452,"title": "Name","page": " <br><br>mdadm - manage MD devices aka Linux Software RAID"},{"id": 18525,"commandid" : 2452,"title": "Synopsis","page": " <br><br><b>mdadm</b> [mode] &lt;raiddevice&gt; [options] &lt;component-devices&gt;"},{"id": 18526,"commandid" : 2452,"title": "Description","page": " <br><br>RAID devices are virtual devices created from two or more real block devices. This allows multiple devices (typically disk drives or partitions thereof) to be combined into a single device to hold (for example) a single filesystem. Some RAID levels include redundancy and so can survive some degree of device failure.<br><br>Linux Software RAID devices are implemented through the md (Multiple Devices) device driver.<br><br>Currently, Linux supports <b>LINEAR</b> md devices, <b>RAID0</b> (striping), <b>RAID1</b> (mirroring), <b>RAID4</b>, <b>RAID5</b>, <b>RAID6</b>, <b>RAID10</b>, <b>MULTIPATH</b>, <b>FAULTY</b>, and <b>CONTAINER</b>.<br><br><b>MULTIPATH</b> is not a Software RAID mechanism, but does involve multiple devices: each device is a path to one common physical storage device. New installations should not use md/multipath as it is not well supported and has no ongoing development. Use the Device Mapper based multipath-tools instead.<br><br><b>FAULTY</b> is also not true RAID, and it only involves one device. It provides a layer over a true device that can be used to inject faults.<br><br><b>CONTAINER</b> is different again. A <b>CONTAINER</b> is a collection of devices that are managed as a set. This is similar to the set of devices connected to a hardware RAID controller. The set of devices may contain a number of different RAID arrays each utilising some (or all) of the blocks from a number of the devices in the set. For example, two devices in a 5-device set might form a RAID1 using the whole devices. The remaining three might have a RAID5 over the first half of each device, and a RAID0 over the second half.<br><br>With a <b>CONTAINER</b>, there is one set of metadata that describes all of the arrays in the container. So when mdadm creates a <b>CONTAINER</b> device, the device just represents the metadata. Other normal arrays (RAID1 etc) can be created inside the container."},{"id": 18527,"commandid" : 2452,"title": "Modes","page": " <br><br>mdadm has several major modes of operation: Assemble Assemble the components of a previously created array into an active array. Components can be explicitly given or can be searched for. mdadm checks that the components do form a bona fide array, and can, on request, fiddle superblock information so as to assemble a faulty array.Build <br><br>Build an array that doesnt have per-device metadata (superblocks). For these sorts of arrays, mdadm cannot differentiate between initial creation and subsequent assembly of an array. It also cannot perform any checks that appropriate components have been requested. Because of this, the <b>Build</b> mode should only be used together with a complete understanding of what you are doing.<br><br><b>Create</b><br><br>Create a new array with per-device metadata (superblocks). Appropriate metadata is written to each device, and then the array comprising those devices is activated. A resync process is started to make sure that the array is consistent (e.g. both sides of a mirror contain the same data) but the content of the device is left otherwise untouched. The array can be used as soon as it has been created. There is no need to wait for the initial resync to finish.Follow or Monitor Monitor one or more md devices and act on any state changes. This is only meaningful for RAID1, 4, 5, 6, 10 or multipath arrays, as only these have interesting state. RAID0 or Linear never have missing, spare, or failed drives, so there is nothing to monitor.Grow <br><br>Grow (or shrink) an array, or otherwise reshape it in some way. Currently supported growth options including changing the active size of component devices and changing the number of active devices in Linear and RAID levels 0/1/4/5/6, changing the RAID level between 0, 1, 5, and 6, and between 0 and 10, changing the chunk size and layout for RAID 0,4,5,6, as well as adding or removing a write-intent bitmap.Incremental Assembly Add a single device to an appropriate array. If the addition of the device makes the array runnable, the array will be started. This provides a convenient interface to a hot-plug system. As each device is detected, mdadm has a chance to include it in some array as appropriate. Optionally, when the --fail flag is passed in we will remove the device from any active array instead of adding it. <p>If a <b>CONTAINER</b> is passed to mdadm in this mode, then any arrays within that container will be assembled and started. </p>Manage <br><br>This is for doing things to specific components of an array such as adding new spares and removing faulty devices.<br><br><b>Misc</b><br><br>This is an everything else mode that supports operations on active arrays, operations on component devices such as erasing old superblocks, and information gathering operations.Auto-detect This mode does not act on a specific device or array, but rather it requests the Linux Kernel to activate any auto-detected arrays. "},{"id": 18528,"commandid" : 2452,"title": "Options","page": " "},{"id": 18529,"commandid" : 2452,"title": "Options for selecting a mode are:","page": " <br><br><b>-A</b>, <b>--assemble</b> Assemble a pre-existing array.-B, --build Build a legacy array without superblocks.-C, --create Create a new array.-F, --follow, --monitor Select <b>Monitor</b> mode.-G, --grow Change the size or shape of an active array.-I, --incremental Add/remove a single device to/from an appropriate array, and possibly start the array.--auto-detect Request that the kernel starts any auto-detected arrays. This can only work if md is compiled into the kernel - not if it is a module. Arrays can be auto-detected by the kernel if all the components are in primary MS-DOS partitions with partition type <b>FD</b>, and all use v0.90 metadata. In-kernel autodetect is not recommended for new installations. Using mdadm to detect and assemble arrays - possibly in an initrd - is substantially more flexible and should be preferred.If a device is given before any options, or if the first option is --add, --fail, or --remove, then the MANAGE mode is assumed. Anything other than these will cause the Misc mode to be assumed. "},{"id": 18530,"commandid" : 2452,"title": "Options that are not mode-specific are:","page": " <br><br><b>-h</b>, <b>--help</b> Display general help message or, after one of the above options, a mode-specific help message.--help-options Display more detailed help about command line parsing and some commonly used options.-V, --version Print version information for mdadm.-v, --verbose Be more verbose about what is happening. This can be used twice to be extra-verbose. The extra verbosity currently only affects <b>--detail --scan</b> and <b>--examine --scan</b>.-q, --quiet Avoid printing purely informative messages. With this, mdadm will be silent unless there is something really important to report.--offroot Set first character of argv[0] to @ to indicate mdadm was launched from initrd/initramfs and should not be shutdown by systemd as part of the regular shutdown process. This option is normally only used by the systems initscripts. Please see here for more details on how systemd handled argv[0]:<b><a href=http://www.freedesktop.org/wiki/Software/systemd/RootStorageDaemons>http://www.freedesktop.org/wiki/Software/systemd/RootStorageDaemons</a></b>-f, --force Be more forceful about certain operations. See the various modes for the exact meaning of this option in different contexts.-c, --config= Specify the config file. Default is to use <b>/etc/mdadm.conf</b>, or if that is missing then <b>/etc/mdadm/mdadm.conf</b>. If the config file given is <b>partitions</b> then nothing will be read, but mdadm will act as though the config file contained exactly <b>DEVICE partitions containers</b> and will read <b>/proc/partitions</b> to find a list of devices to scan, and <b>/proc/mdstat</b> to find a list of containers to examine. If the word <b>none</b> is given for the config file, then mdadm will act as though the config file were empty.-s, --scan Scan config file or <b>/proc/mdstat</b> for missing information. In general, this option gives mdadm permission to get any missing information (like component devices, array devices, array identities, and alert destination) from the configuration file (see previous option); one exception is MISC mode when using <b>--detail</b> or <b>--stop,</b> in which case <b>--scan</b> says to get a list of array devices from <b>/proc/mdstat</b>.-e, --metadata= Declare the style of RAID metadata (superblock) to be used. The default is 1.2 for <b>--create</b>, and to guess for other operations. The default can be overridden by setting the <b>metadata</b> value for the <b>CREATE</b> keyword in <b>mdadm.conf</b>. <p>Options are: </p>0, 0.90 <br><br>Use the original 0.90 format superblock. This format limits arrays to 28 component devices and limits component devices of levels 1 and greater to 2 terabytes. It is also possible for there to be confusion about whether the superblock applies to a whole device or just the last partition, if that partition starts on a 64K boundary. 1, 1.0, 1.1, 1.2 default <br><br>Use the new version-1 format superblock. This has fewer restrictions. It can easily be moved between hosts with different endian-ness, and a recovery operation can be checkpointed and restarted. The different sub-versions store the superblock at different locations on the device, either at the end (for 1.0), at the start (for 1.1) or 4K from the start (for 1.2). 1 is equivalent to 1.2 (the commonly preferred 1.x format). default is equivalent to 1.2. ddf <p>Use the Industry Standard DDF (Disk Data Format) format defined by SNIA. When creating a DDF array a <b>CONTAINER</b> will be created, and normal arrays can be created in that container. </p><p>imsm </p><p>Use the <b>Intel</b>(R) Matrix Storage Manager metadata format. This creates a <b>CONTAINER</b> which is managed in a similar manner to DDF, and is supported by an option-rom on some platforms: </p> <br><br><b><a href=http://www.intel.com/design/chipsets/matrixstorage_sb.htm>http://www.intel.com/design/chipsets/matrixstorage_sb.htm</a></b> --homehost= This will override any <b>HOMEHOST</b> setting in the config file and provides the identity of the host which should be considered the home for any arrays. <p>When creating an array, the <b>homehost</b> will be recorded in the metadata. For version-1 superblocks, it will be prefixed to the array name. For version-0.90 superblocks, part of the SHA1 hash of the hostname will be stored in the later half of the UUID. </p><p>When reporting information about an array, any array which is tagged for the given homehost will be reported as such. </p><p>When using Auto-Assemble, only arrays tagged for the given homehost will be allowed to use local names (i.e. not ending in _ followed by a digit string). See below under <b>Auto Assembly</b>. </p>--prefer= When mdadm needs to print the name for a device it normally finds the name in <b>/dev</b> which refers to the device and is shortest. When a path component is given with <b>--prefer</b> mdadm will prefer a longer name if it contains that component. For example <b>--prefer=by-uuid</b> will prefer a name in a subdirectory of <b>/dev</b> called <b>by-uuid</b>. <p>This functionality is currently only provided by <b>--detail</b> and <b>--monitor</b>. </p> "},{"id": 18531,"commandid" : 2452,"title": "For create, build, or grow:","page": " <br><br><b>-n</b>, <b>--raid-devices=</b> Specify the number of active devices in the array. This, plus the number of spare devices (see below) must equal the number of component-devices (including <b>missing</b> devices) that are listed on the command line for <b>--create</b>. Setting a value of 1 is probably a mistake and so requires that <b>--force</b> be specified first. A value of 1 will then be allowed for linear, multipath, RAID0 and RAID1. It is never allowed for RAID4, RAID5 or RAID6.<br> This number can only be changed using <b>--grow</b> for RAID1, RAID4, RAID5 and RAID6 arrays, and only on kernels which provide the necessary support.-x, --spare-devices= Specify the number of spare (eXtra) devices in the initial array. Spares can also be added and removed later. The number of component devices listed on the command line must equal the number of RAID devices plus the number of spare devices.-z, --size= Amount (in Kibibytes) of space to use from each drive in RAID levels 1/4/5/6. This must be a multiple of the chunk size, and must leave about 128Kb of space at the end of the drive for the RAID superblock. If this is not specified (as it normally is not) the smallest drive (or partition) sets the size, though if there is a variance among the drives of greater than 1%, a warning is issued. <p>A suffix of M or G can be given to indicate Megabytes or Gigabytes respectively. </p><p>Sometimes a replacement drive can be a little smaller than the original drives though this should be minimised by IDEMA standards. Such a replacement drive will be rejected by md. To guard against this it can be useful to set the initial size slightly smaller than the smaller device with the aim that it will still be larger than any replacement. </p><p>This value can be set with <b>--grow</b> for RAID level 1/4/5/6 though <b>CONTAINER</b> based arrays such as those with IMSM metadata may not be able to support this. If the array was created with a size smaller than the currently active drives, the extra space can be accessed using <b>--grow</b>. The size can be given as <b>max</b> which means to choose the largest size that fits on all current drives. </p><p>Before reducing the size of the array (with <b>--grow --size=</b>) you should make sure that space isnt needed. If the device holds a filesystem, you would need to resize the filesystem to use less space. </p><p>After reducing the array size you should check that the data stored in the device is still available. If the device holds a filesystem, then an fsck of the filesystem is a minimum requirement. If there are problems the array can be made bigger again with no loss with another <b>--grow --size=</b> command. </p><p>This value cannot be used when creating a <b>CONTAINER</b> such as with DDF and IMSM metadata, though it perfectly valid when creating an array inside a container. </p>-Z, --array-size= This is only meaningful with <b>--grow</b> and its effect is not persistent: when the array is stopped and restarted the default array size will be restored. <p>Setting the array-size causes the array to appear smaller to programs that access the data. This is particularly needed before reshaping an array so that it will be smaller. As the reshape is not reversible, but setting the size with <b>--array-size</b> is, it is required that the array size is reduced as appropriate before the number of devices in the array is reduced. </p><p>Before reducing the size of the array you should make sure that space isnt needed. If the device holds a filesystem, you would need to resize the filesystem to use less space. </p><p>After reducing the array size you should check that the data stored in the device is still available. If the device holds a filesystem, then an fsck of the filesystem is a minimum requirement. If there are problems the array can be made bigger again with no loss with another <b>--grow --array-size=</b> command. </p><p>A suffix of M or G can be given to indicate Megabytes or Gigabytes respectively. A value of <b>max</b> restores the apparent size of the array to be whatever the real amount of available space is. </p>-c, --chunk= Specify chunk size of kibibytes. The default when creating an array is 512KB. To ensure compatibility with earlier versions, the default when Building and array with no persistent metadata is 64KB. This is only meaningful for RAID0, RAID4, RAID5, RAID6, and RAID10. <p>RAID4, RAID5, RAID6, and RAID10 require the chunk size to be a power of 2. In any case it must be a multiple of 4KB. </p><p>A suffix of M or G can be given to indicate Megabytes or Gigabytes respectively. </p>--rounding= Specify rounding factor for a Linear array. The size of each component will be rounded down to a multiple of this size. This is a synonym for <b>--chunk</b> but highlights the different meaning for Linear as compared to other RAID levels. The default is 64K if a kernel earlier than 2.6.16 is in use, and is 0K (i.e. no rounding) in later kernels.-l, --level= Set RAID level. When used with <b>--create</b>, options are: linear, raid0, 0, stripe, raid1, 1, mirror, raid4, 4, raid5, 5, raid6, 6, raid10, 10, multipath, mp, faulty, container. Obviously some of these are synonymous. <p>When a <b>CONTAINER</b> metadata type is requested, only the <b>container</b> level is permitted, and it does not need to be explicitly given. </p><p>When used with <b>--build</b>, only linear, stripe, raid0, 0, raid1, multipath, mp, and faulty are valid. </p><p>Can be used with <b>--grow</b> to change the RAID level in some cases. See LEVEL CHANGES below. </p>-p, --layout= This option configures the fine details of data layout for RAID5, RAID6, and RAID10 arrays, and controls the failure modes for faulty. <p>The layout of the RAID5 parity block can be one of <b>left-asymmetric</b>, <b>left-symmetric</b>, <b>right-asymmetric</b>, <b>right-symmetric</b>, <b>la</b>, <b>ra</b>, <b>ls</b>, <b>rs</b>. The default is <b>left-symmetric</b>. </p><p>It is also possible to cause RAID5 to use a RAID4-like layout by choosing <b>parity-first</b>, or <b>parity-last</b>. </p><p>Finally for RAID5 there are DDF-compatible layouts, <b>ddf-zero-restart</b>, <b>ddf-N-restart</b>, and <b>ddf-N-continue</b>. </p><p>These same layouts are available for RAID6. There are also 4 layouts that will provide an intermediate stage for converting between RAID5 and RAID6. These provide a layout which is identical to the corresponding RAID5 layout on the first N-1 devices, and has the Q syndrome (the second parity block used by RAID6) on the last device. These layouts are: <b>left-symmetric-6</b>, <b>right-symmetric-6</b>, <b>left-asymmetric-6</b>, <b>right-asymmetric-6</b>, and <b>parity-first-6</b>. </p><p>When setting the failure mode for level faulty, the options are: <b>write-transient</b>, <b>wt</b>, <b>read-transient</b>, <b>rt</b>, <b>write-persistent</b>, <b>wp</b>, <b>read-persistent</b>, <b>rp</b>, <b>write-all</b>, <b>read-fixable</b>, <b>rf</b>, <b>clear</b>, <b>flush</b>, <b>none</b>. </p><p>Each failure mode can be followed by a number, which is used as a period between fault generation. Without a number, the fault is generated once on the first relevant request. With a number, the fault will be generated after that many requests, and will continue to be generated every time the period elapses. </p><p>Multiple failure modes can be current simultaneously by using the <b>--grow</b> option to set subsequent failure modes. </p><p>clear or none will remove any pending or periodic failure modes, and flush will clear any persistent faults. </p><p>Finally, the layout options for RAID10 are one of n, o or f followed by a small number. The default is n2. The supported options are: </p><p>n signals near copies. Multiple copies of one data block are at similar offsets in different devices. </p><p>o signals offset copies. Rather than the chunks being duplicated within a stripe, whole stripes are duplicated but are rotated by one device so duplicate blocks are on different devices. Thus subsequent copies of a block are in the next drive, and are one chunk further down. </p><p>f signals far copies (multiple copies have very different offsets). See <b><a href=/man/4/md>md</a></b>(4) for more detail about near, offset, and far. </p><p>The number is the number of copies of each datablock. 2 is normal, 3 can be useful. This number can be at most equal to the number of devices in the array. It does not need to divide evenly into that number (e.g. it is perfectly legal to have an n2 layout for an array with an odd number of devices). </p><p>When an array is converted between RAID5 and RAID6 an intermediate RAID6 layout is used in which the second parity block (Q) is always on the last device. To convert a RAID5 to RAID6 and leave it in this new layout (which does not require re-striping) use <b>--layout=preserve</b>. This will try to avoid any restriping. </p><p>The converse of this is <b>--layout=normalise</b> which will change a non-standard RAID6 layout into a more standard arrangement. </p>--parity= same as <b>--layout</b> (thus explaining the p of <b>-p</b>).-b, --bitmap= Specify a file to store a write-intent bitmap in. The file should not exist unless <b>--force</b> is also given. The same file should be provided when assembling the array. If the word <b>internal</b> is given, then the bitmap is stored with the metadata on the array, and so is replicated on all devices. If the word <b>none</b> is given with <b>--grow</b> mode, then any bitmap that is present is removed. <p>To help catch typing errors, the filename must contain at least one slash (/) if it is a real file (not internal or none). </p><p>Note: external bitmaps are only known to work on ext2 and ext3. Storing bitmap files on other filesystems may result in serious problems. </p>--bitmap-chunk= Set the chunksize of the bitmap. Each bit corresponds to that many Kilobytes of storage. When using a file based bitmap, the default is to use the smallest size that is at-least 4 and requires no more than 2^21 chunks. When using an <b>internal</b> bitmap, the chunksize defaults to 64Meg, or larger if necessary to fit the bitmap into the available space. <p>A suffix of M or G can be given to indicate Megabytes or Gigabytes respectively. </p>-W, --write-mostly subsequent devices listed in a <b>--build</b>, <b>--create</b>, or <b>--add</b> command will be flagged as write-mostly. This is valid for RAID1 only and means that the md driver will avoid reading from these devices if at all possible. This can be useful if mirroring over a slow link.--write-behind= Specify that write-behind mode should be enabled (valid for RAID1 only). If an argument is specified, it will set the maximum number of outstanding writes allowed. The default value is 256. A write-intent bitmap is required in order to use write-behind mode, and write-behind is only attempted on drives marked as write-mostly.--assume-clean Tell mdadm that the array pre-existed and is known to be clean. It can be useful when trying to recover from a major failure as you can be sure that no data will be affected unless you actually write to the array. It can also be used when creating a RAID1 or RAID10 if you want to avoid the initial resync, however this practice - while normally safe - is not recommended. Use this only if you really know what you are doing.When the devices that will be part of a new array were filled with zeros before creation the operator knows the array is actually clean. If that is the case, such as after running badblocks, this argument can be used to tell mdadm the facts the operator knows. <p>When an array is resized to a larger size with <b>--grow --size=</b> the new space is normally resynced in that same way that the whole array is resynced at creation. From Linux version 3.0, <b>--assume-clean</b> can be used with that command to avoid the automatic resync. </p>--backup-file= This is needed when <b>--grow</b> is used to increase the number of raid-devices in a RAID5 or RAID6 if there are no spare devices available, or to shrink, change RAID level or layout. See the GROW MODE section below on RAID-DEVICES CHANGES. The file must be stored on a separate device, not on the RAID array being reshaped.--continue This option is complementary to the <b>--freeze-reshape</b> option for assembly. It is needed when <b>--grow</b> operation is interrupted and it is not restarted automatically due to <b>--freeze-reshape</b> usage during array assembly. This option is used together with <b>-G</b> , ( <b>--grow</b> ) command and device for a pending reshape to be continued. All parameters required for reshape continuation will be read from array metadata. If initial <b>--grow</b> command had required <b>--backup-file=</b> option to be set, continuation option will require to have exactly the same backup file given as well.Any other parameter passed together with <b>--continue</b> option will be ignored.-N, --name= Set a <b>name</b> for the array. This is currently only effective when creating an array with a version-1 superblock, or an array in a DDF container. The name is a simple textual string that can be used to identify array components when assembling. If name is needed but not specified, it is taken from the basename of the device that is being created. e.g. when creating /dev/md/home the <b>name</b> will default to home.-R, --run Insist that mdadm run the array, even if some of the components appear to be active in another array or filesystem. Normally mdadm will ask for confirmation before including such components in an array. This option causes that question to be suppressed.-f, --force Insist that mdadm accept the geometry and layout specified without question. Normally mdadm will not allow creation of an array with only one device, and will try to create a RAID5 array with one missing drive (as this makes the initial resync work faster). With <b>--force</b>, mdadm will not try to be so clever.-a, --auto{=yes,md,mdp,part,p}{NN} Instruct mdadm how to create the device file if needed, possibly allocating an unused minor number. md causes a non-partitionable array to be used (though since Linux 2.6.28, these array devices are in fact partitionable). mdp, part or p causes a partitionable array (2.6 and later) to be used. yes requires the named md device to have a standard format, and the type and minor number will be determined from this. With mdadm 3.0, device creation is normally left up to udev so this option is unlikely to be needed. See DEVICE NAMES below. <p>The argument can also come immediately after -a. e.g. -ap. </p><p>If <b>--auto</b> is not given on the command line or in the config file, then the default will be <b>--auto=yes</b>. </p><p>If <b>--scan</b> is also given, then any auto= entries in the config file will override the <b>--auto</b> instruction given on the command line. </p><p>For partitionable arrays, mdadm will create the device file for the whole array and for the first 4 partitions. A different number of partitions can be specified at the end of this option (e.g. <b>--auto=p7</b>). If the device name ends with a digit, the partition names add a p, and a number, e.g. /dev/md/home1p3. If there is no trailing digit, then the partition names just have a number added, e.g. /dev/md/scratch3. </p><p>If the md device name is in a standard format as described in DEVICE NAMES, then it will be created, if necessary, with the appropriate device number based on that name. If the device name is not in one of these formats, then a unused device number will be allocated. The device number will be considered unused if there is no active array for that number, and there is no entry in /dev for that number and with a non-standard name. Names that are not in standard format are only allowed in /dev/md/. </p><p>This is meaningful with <b>--create</b> or <b>--build</b>. </p>-a, --add This option can be used in Grow mode in two cases. <p>If the target array is a Linear array, then <b>--add</b> can be used to add one or more devices to the array. They are simply catenated on to the end of the array. Once added, the devices cannot be removed. </p><p>If the <b>--raid-disks</b> option is being used to increase the number of devices in an array, then <b>--add</b> can be used to add some extra devices to be included in the array. In most cases this is not needed as the extra devices can be added as spares first, and then the number of raid-disks can be changed. However for RAID0, it is not possible to add spares. So to increase the number of devices in a RAID0, it is necessary to set the new number of devices, and to add the new devices, in the same command. </p> "},{"id": 18532,"commandid" : 2452,"title": "For assemble:","page": " <br><br><b>-u</b>, <b>--uuid=</b> uuid of array to assemble. Devices which dont have this uuid are excluded-m, --super-minor= Minor number of device that array was created for. Devices which dont have this minor number are excluded. If you create an array as /dev/md1, then all superblocks will contain the minor number 1, even if the array is later assembled as /dev/md2. <p>Giving the literal word dev for <b>--super-minor</b> will cause mdadm to use the minor number of the md device that is being assembled. e.g. when assembling <b>/dev/md0</b>, <b>--super-minor=dev</b> will look for super blocks with a minor number of 0. </p><p><b>--super-minor</b> is only relevant for v0.90 metadata, and should not normally be used. Using <b>--uuid</b> is much safer. </p>-N, --name= Specify the name of the array to assemble. This must be the name that was specified when creating the array. It must either match the name stored in the superblock exactly, or it must match with the current homehost prefixed to the start of the given name.-f, --force Assemble the array even if the metadata on some devices appears to be out-of-date. If mdadm cannot find enough working devices to start the array, but can find some devices that are recorded as having failed, then it will mark those devices as working so that the array can be started. An array which requires <b>--force</b> to be started may contain data corruption. Use it carefully.-R, --run Attempt to start the array even if fewer drives were given than were present last time the array was active. Normally if not all the expected drives are found and <b>--scan</b> is not used, then the array will be assembled but not started. With <b>--run</b> an attempt will be made to start it anyway.--no-degraded This is the reverse of <b>--run</b> in that it inhibits the startup of array unless all expected drives are present. This is only needed with <b>--scan,</b> and can be used if the physical connections to devices are not as reliable as you would like.-a, --auto{=no,yes,md,mdp,part} See this option under Create and Build options.-b, --bitmap= Specify the bitmap file that was given when the array was created. If an array has an <b>internal</b> bitmap, there is no need to specify this when assembling the array.--backup-file= If <b>--backup-file</b> was used while reshaping an array (e.g. changing number of devices or chunk size) and the system crashed during the critical section, then the same <b>--backup-file</b> must be presented to <b>--assemble</b> to allow possibly corrupted data to be restored, and the reshape to be completed.--invalid-backup If the file needed for the above option is not available for any reason an empty file can be given together with this option to indicate that the backup file is invalid. In this case the data that was being rearranged at the time of the crash could be irrecoverably lost, but the rest of the array may still be recoverable. This option should only be used as a last resort if there is no way to recover the backup file.-U, --update= Update the superblock on each device while assembling the array. The argument given to this flag can be one of <b>sparc2.2</b>, <b>summaries</b>, <b>uuid</b>, <b>name</b>, <b>homehost</b>, <b>resync</b>, <b>byteorder</b>, <b>devicesize</b>, <b>no-bitmap</b>, or <b>super-minor</b>. <p>The <b>sparc2.2</b> option will adjust the superblock of an array what was created on a Sparc machine running a patched 2.2 Linux kernel. This kernel got the alignment of part of the superblock wrong. You can use the <b>--examine --sparc2.2</b> option to mdadm to see what effect this would have. </p><p>The <b>super-minor</b> option will update the <b>preferred minor</b> field on each superblock to match the minor number of the array being assembled. This can be useful if <b>--examine</b> reports a different Preferred Minor to <b>--detail</b>. In some cases this update will be performed automatically by the kernel driver. In particular the update happens automatically at the first write to an array with redundancy (RAID level 1 or greater) on a 2.6 (or later) kernel. </p><p>The <b>uuid</b> option will change the uuid of the array. If a UUID is given with the <b>--uuid</b> option that UUID will be used as a new UUID and will <b>NOT</b> be used to help identify the devices in the array. If no <b>--uuid</b> is given, a random UUID is chosen. </p><p>The <b>name</b> option will change the name of the array as stored in the superblock. This is only supported for version-1 superblocks. </p><p>The <b>homehost</b> option will change the homehost as recorded in the superblock. For version-0 superblocks, this is the same as updating the UUID. For version-1 superblocks, this involves updating the name. </p><p>The <b>resync</b> option will cause the array to be marked dirty meaning that any redundancy in the array (e.g. parity for RAID5, copies for RAID1) may be incorrect. This will cause the RAID system to perform a resync pass to make sure that all redundant information is correct. </p><p>The <b>byteorder</b> option allows arrays to be moved between machines with different byte-order. When assembling such an array for the first time after a move, giving <b>--update=byteorder</b> will cause mdadm to expect superblocks to have their byteorder reversed, and will correct that order before assembling the array. This is only valid with original (Version 0.90) superblocks. </p><p>The <b>summaries</b> option will correct the summaries in the superblock. That is the counts of total, working, active, failed, and spare devices. </p><p>The <b>devicesize</b> option will rarely be of use. It applies to version 1.1 and 1.2 metadata only (where the metadata is at the start of the device) and is only useful when the component device has changed size (typically become larger). The version 1 metadata records the amount of the device that can be used to store data, so if a device in a version 1.1 or 1.2 array becomes larger, the metadata will still be visible, but the extra space will not. In this case it might be useful to assemble the array with <b>--update=devicesize</b>. This will cause mdadm to determine the maximum usable amount of space on each device and update the relevant field in the metadata. </p><p>The <b>no-bitmap</b> option can be used when an array has an internal bitmap which is corrupt in some way so that assembling the array normally fails. It will cause any internal bitmap to be ignored. </p>--freeze-reshape Option is intended to be used in start-up scripts during initrd boot phase. When array under reshape is assembled during initrd phase, this option stops reshape after reshape critical section is being restored. This happens before file system pivot operation and avoids loss of file system context. Losing file system context would cause reshape to be broken. <p>Reshape can be continued later using the <b>--continue</b> option for the grow command. </p> "},{"id": 18533,"commandid" : 2452,"title": "For Manage mode:","page": " <br><br><b>-t</b>, <b>--test</b> Unless a more serious error occurred, mdadm will exit with a status of 2 if no changes were made to the array and 0 if at least one change was made. This can be useful when an indirect specifier such as <b>missing</b>, <b>detached</b> or <b>faulty</b> is used in requesting an operation on the array. <b>--test</b> will report failure if these specifiers didnt find any match.-a, --add hot-add listed devices. If a device appears to have recently been part of the array (possibly it failed or was removed) the device is re-added as described in the next point. If that fails or the device was never part of the array, the device is added as a hot-spare. If the array is degraded, it will immediately start to rebuild data onto that spare. <p>Note that this and the following options are only meaningful on array with redundancy. They dont apply to RAID0 or Linear. </p>--re-add re-add a device that was previous removed from an array. If the metadata on the device reports that it is a member of the array, and the slot that it used is still vacant, then the device will be added back to the array in the same position. This will normally cause the data for that device to be recovered. However based on the event count on the device, the recovery may only require sections that are flagged a write-intent bitmap to be recovered or may not require any recovery at all. <p>When used on an array that has no metadata (i.e. it was built with <b>--build)</b> it will be assumed that bitmap-based recovery is enough to make the device fully consistent with the array. </p><p>When <b>--re-add</b> can be accompanied by <b>--update=devicesize</b>. See the description of this option when used in Assemble mode for an explanation of its use. </p><p>If the device name given is <b>missing</b> then mdadm will try to find any device that looks like it should be part of the array but isnt and will try to re-add all such devices. </p>-r, --remove remove listed devices. They must not be active. i.e. they should be failed or spare devices. As well as the name of a device file (e.g. <b>/dev/sda1</b>) the words <b>failed</b> and <b>detached</b> can be given to <b>--remove</b>. The first causes all failed device to be removed. The second causes any device which is no longer connected to the system (i.e an open returns <b>ENXIO</b>) to be removed. This will only succeed for devices that are spares or have already been marked as failed.-f, --fail mark listed devices as faulty. As well as the name of a device file, the word <b>detached</b> can be given. This will cause any device that has been detached from the system to be marked as failed. It can then be removed.--set-faulty same as <b>--fail</b>.--write-mostly Subsequent devices that are added or re-added will have the write-mostly flag set. This is only valid for RAID1 and means that the md driver will avoid reading from these devices if possible.--readwrite Subsequent devices that are added or re-added will have the write-mostly flag cleared.Each of these options requires that the first device listed is the array to be acted upon, and the remainder are component devices to be added, removed, marked as faulty, etc. Several different operations can be specified for different devices, e.g. mdadm /dev/md0 --add /dev/sda1 --fail /dev/sdb1 --remove /dev/sdb1Each operation applies to all devices listed until the next operation. <br><br>If an array is using a write-intent bitmap, then devices which have been removed can be re-added in a way that avoids a full reconstruction but instead just updates the blocks that have changed since the device was removed. For arrays with persistent metadata (superblocks) this is done automatically. For arrays created with <b>--build</b> mdadm needs to be told that this device we removed recently with <b>--re-add</b>.<br><br>Devices can only be removed from an array if they are not in active use, i.e. that must be spares or failed devices. To remove an active device, it must first be marked as <b>faulty.</b> "},{"id": 18534,"commandid" : 2452,"title": "For Misc mode:","page": " <br><br><b>-Q</b>, <b>--query</b> Examine a device to see (1) if it is an md device and (2) if it is a component of an md array. Information about what is discovered is presented.-D, --detail Print details of one or more md devices.--detail-platform Print details of the platforms RAID capabilities (firmware / hardware topology) for a given metadata format.-Y, --export When used with <b>--detail</b> or <b>--examine</b>, output will be formatted as <b>key=value</b> pairs for easy import into the environment.-E, --examine Print contents of the metadata stored on the named <b>device</b>(s). Note the contrast between <b>--examine</b> and <b>--detail</b>. <b>--examine</b> applies to devices which are components of an array, while <b>--detail</b> applies to a whole array which is currently active.--sparc2.2 If an array was created on a SPARC machine with a 2.2 Linux kernel patched with RAID support, the superblock will have been created incorrectly, or at least incompatibly with 2.4 and later kernels. Using the <b>--sparc2.2</b> flag with <b>--examine</b> will fix the superblock before displaying it. If this appears to do the right thing, then the array can be successfully assembled using <b>--assemble --update=sparc2.2</b>.-X, --examine-bitmap Report information about a bitmap file. The argument is either an external bitmap file or an array component in case of an internal bitmap. Note that running this on an array device (e.g. <b>/dev/md0</b>) does not report the bitmap for that array.-R, --run start a partially assembled array. If <b>--assemble</b> did not find enough devices to fully start the array, it might leaving it partially assembled. If you wish, you can then use <b>--run</b> to start the array in degraded mode.-S, --stop deactivate array, releasing all resources.-o, --readonly mark array as readonly.-w, --readwrite mark array as readwrite.--zero-superblock If the device contains a valid md superblock, the block is overwritten with zeros. With <b>--force</b> the block where the superblock would be is overwritten even if it doesnt appear to be valid.--kill-subarray= If the device is a container and the argument to --kill-subarray specifies an inactive subarray in the container, then the subarray is deleted. Deleting all subarrays will leave an empty-container or spare superblock on the drives. See --zero-superblock for completely removing a superblock. Note that some formats depend on the subarray index for generating a UUID, this command will fail if it would change the UUID of an active subarray.--update-subarray= If the device is a container and the argument to --update-subarray specifies a subarray in the container, then attempt to update the given superblock field in the subarray. See below in <b>MISC MODE</b> for details.-t, --test When used with <b>--detail</b>, the exit status of mdadm is set to reflect the status of the device. See below in <b>MISC MODE</b> for details.-W, --wait For each md device given, wait for any resync, recovery, or reshape activity to finish before returning. mdadm will return with success if it actually waited for every device listed, otherwise it will return failure.--wait-clean For each md device given, or each device in /proc/mdstat if <b>--scan</b> is given, arrange for the array to be marked clean as soon as possible. mdadm will return with success if the array uses external metadata and we successfully waited. For native arrays this returns immediately as the kernel handles dirty-clean transitions at shutdown. No action is taken if safe-mode handling is disabled. "},{"id": 18535,"commandid" : 2452,"title": "For Incremental Assembly mode:","page": " <br><br><b>--rebuild-map</b>, <b>-r</b> Rebuild the map file (<b>/dev/md/md-device-map</b>) that mdadm uses to help track which arrays are currently being assembled.--run, -R Run any array assembled as soon as a minimal number of devices are available, rather than waiting until all expected devices are present.--scan, -s Only meaningful with <b>-R</b> this will scan the <b>map</b> file for arrays that are being incrementally assembled and will try to start any that are not already started. If any such array is listed in <b>mdadm.conf</b> as requiring an external bitmap, that bitmap will be attached first.--fail, -f This allows the hot-plug system to remove devices that have fully disappeared from the kernel. It will first fail and then remove the device from any array it belongs to. The device name given should be a kernel device name such as sda, not a name in /dev.--path= Only used with --fail. The path given will be recorded so that if a new device appears at the same location it can be automatically added to the same array. This allows the failed device to be automatically replaced by a new device without metadata if it appears at specified path. This option is normally only set by a udev script. "},{"id": 18536,"commandid" : 2452,"title": "For Monitor mode:","page": " <br><br><b>-m</b>, <b>--mail</b> Give a mail address to send alerts to.-p, --program, --alert Give a program to be run whenever an event is detected.-y, --syslog Cause all events to be reported through syslog. The messages have facility of daemon and varying priorities.-d, --delay Give a delay in seconds. mdadm polls the md arrays and then waits this many seconds before polling again. The default is 60 seconds. Since 2.6.16, there is no need to reduce this as the kernel alerts mdadm immediately when there is any change.-r, --increment Give a percentage increment. mdadm will generate RebuildNN events with the given percentage increment.-f, --daemonise Tell mdadm to run as a background daemon if it decides to monitor anything. This causes it to fork and run in the child, and to disconnect from the terminal. The process id of the child is written to stdout. This is useful with <b>--scan</b> which will only continue monitoring if a mail address or alert program is found in the config file.-i, --pid-file When mdadm is running in daemon mode, write the pid of the daemon process to the specified file, instead of printing it on standard output.-1, --oneshot Check arrays only once. This will generate <b>NewArray</b> events and more significantly <b>DegradedArray</b> and <b>SparesMissing</b> events. Running<b>mdadm --monitor --scan -1</b>from a cron script will ensure regular notification of any degraded arrays.-t, --test Generate a <b>TestMessage</b> alert for every array found at startup. This alert gets mailed and passed to the alert program. This can be used for testing that alert message do get through successfully.--no-sharing This inhibits the functionality for moving spares between arrays. Only one monitoring process started with <b>--scan</b> but without this flag is allowed, otherwise the two could interfere with each other. "},{"id": 18537,"commandid" : 2452,"title": "Assemble Mode","page": " <br><br>Usage: <b>mdadm --assemble</b> md-device options-and-component-devices... mdadm --assemble --scan mdadm --assemble --scan <br><br>In the first usage example (without the <b>--scan</b>) the first device given is the md device. In the second usage example, all devices listed are treated as md devices and assembly is attempted. In the third (where no devices are listed) all md devices that are listed in the configuration file are assembled. If no arrays are described by the configuration file, then any arrays that can be found on unused devices will be assembled.<br><br>If precisely one device is listed, but <b>--scan</b> is not given, then mdadm acts as though <b>--scan</b> was given and identity information is extracted from the configuration file.<br><br>The identity can be given with the <b>--uuid</b> option, the <b>--name</b> option, or the <b>--super-minor</b> option, will be taken from the md-device record in the config file, or will be taken from the super block of the first component-device listed on the command line.<br><br>Devices can be given on the <b>--assemble</b> command line or in the config file. Only devices which have an md superblock which contains the right identity will be considered for any array.<br><br>The config file is only used if explicitly named with <b>--config</b> or requested with (a possibly implicit) <b>--scan</b>. In the later case, <b>/etc/mdadm.conf</b> or <b>/etc/mdadm/mdadm.conf</b> is used.<br><br>If <b>--scan</b> is not given, then the config file will only be used to find the identity of md arrays.<br><br>Normally the array will be started after it is assembled. However if <b>--scan</b> is not given and not all expected drives were listed, then the array is not started (to guard against usage errors). To insist that the array be started in this case (as may work for RAID1, 4, 5, 6, or 10), give the <b>--run</b> flag.<br><br>If udev is active, mdadm does not create any entries in <b>/dev</b> but leaves that to udev. It does record information in <b>/dev/md/md-device-map</b> which will allow udev to choose the correct name.<br><br>If mdadm detects that udev is not configured, it will create the devices in <b>/dev</b> itself.<br><br>In Linux kernels prior to version 2.6.28 there were two distinctly different types of md devices that could be created: one that could be partitioned using standard partitioning tools and one that could not. Since 2.6.28 that distinction is no longer relevant as both type of devices can be partitioned. mdadm will normally create the type that originally could not be partitioned as it has a well defined major number (9).<br><br>Prior to 2.6.28, it is important that mdadm chooses the correct type of array device to use. This can be controlled with the <b>--auto</b> option. In particular, a value of mdp or part or p tells mdadm to use a partitionable device rather than the default.<br><br>In the no-udev case, the value given to <b>--auto</b> can be suffixed by a number. This tells mdadm to create that number of partition devices rather than the default of 4.<br><br>The value given to <b>--auto</b> can also be given in the configuration file as a word starting <b>auto=</b> on the ARRAY line for the relevant array. <br><br><b>Auto Assembly</b> --assemble is used with --scan and no devices are listed, <br><br>If no arrays are listed in the config (other than those marked <b>&lt;ignore&gt;</b>) it will look through the available devices for possible arrays and will try to assemble anything that it finds. Arrays which are tagged as belonging to the given homehost will be assembled and started normally. Arrays which do not obviously belong to this host are given names that are expected not to conflict with anything local, and are started read-auto so that nothing is written to any device until the array is written to. i.e. automatic resync etc is delayed.<br><br>If mdadm finds a consistent set of devices that look like they should comprise an array, and if the superblock is tagged as belonging to the given home host, it will automatically choose a device name and try to assemble the array. If the array uses version-0.90 metadata, then the <b>minor</b> number as recorded in the superblock is used to create a name in <b>/dev/md/</b> so for example <b>/dev/md/3</b>. If the array uses version-1 metadata, then the <b>name</b> from the superblock is used to similarly create a name in <b>/dev/md/</b> (the name will have any host prefix stripped first).<br><br>This behaviour can be modified by the AUTO line in the mdadm.conf configuration file. This line can indicate that specific metadata type should, or should not, be automatically assembled. If an array is found which is not listed in mdadm.conf and has a metadata format that is denied by the AUTO line, then it will not be assembled. The AUTO line can also request that all arrays identified as being for this homehost should be assembled regardless of their metadata type. See <b><a href=/man/5/mdadm.conf>mdadm.conf</a></b>(5) for further details.<br><br>Note: Auto assembly cannot be used for assembling and activating some arrays which are undergoing reshape. In particular as the <b>backup-file</b> cannot be given, any reshape which requires a backup-file to continue cannot be started by auto assembly. An array which is growing to more devices and has passed the critical section can be assembled using auto-assembly. "},{"id": 18538,"commandid" : 2452,"title": "Build Mode","page": " <br><br>Usage: <b>mdadm --build</b> md-device <b>--chunk=</b>X <b>--level=</b>Y <b>--raid-devices=</b>Z devices --create. The difference is that it creates an array without a superblock. With these arrays there is no difference between initially creating the array and subsequently assembling the array, except that hopefully there is useful data there in the second case. <br><br>The level may raid0, linear, raid1, raid10, multipath, or faulty, or one of their synonyms. All devices must be listed and the array will be started once complete. It will often be appropriate to use <b>--assume-clean</b> with levels raid1 or raid10. "},{"id": 18539,"commandid" : 2452,"title": "Create Mode","page": " <br><br>Usage: <b>mdadm --create</b> md-device <b>--chunk=</b>X <b>--level=</b>Y <b>--raid-devices=</b>Z devicesThis usage will initialise a new md array, associate some devices with it, and activate the array. <br><br>The named device will normally not exist when mdadm --create is run, but will be created by udev once the array becomes active.<br><br>As devices are added, they are checked to see if they contain RAID superblocks or filesystems. They are also checked to see if the variance in device size exceeds 1%.<br><br>If any discrepancy is found, the array will not automatically be run, though the presence of a <b>--run</b> can override this caution.<br><br>To create a degraded array in which some devices are missing, simply give the word <b>missing</b> in place of a device name. This will cause mdadm to leave the corresponding slot in the array empty. For a RAID4 or RAID5 array at most one slot can be <b>missing</b>; for a RAID6 array at most two slots. For a RAID1 array, only one real device needs to be given. All of the others can be <b>missing</b>.<br><br>When creating a RAID5 array, mdadm will automatically create a degraded array with an extra spare drive. This is because building the spare into a degraded array is in general faster than resyncing the parity on a non-degraded, but not clean, array. This feature can be overridden with the <b>--force</b> option.<br><br>When creating an array with version-1 metadata a name for the array is required. If this is not given with the <b>--name</b> option, mdadm will choose a name based on the last component of the name of the device being created. So if <b>/dev/md3</b> is being created, then the name <b>3</b> will be chosen. If <b>/dev/md/home</b> is being created, then the name <b>home</b> will be used.<br><br>When creating a partition based array, using mdadm with version-1.x metadata, the partition type should be set to <b>0xDA</b> (non fs-data). This type selection allows for greater precision since using any other [RAID auto-detect (0xFD) or a GNU/Linux partition (0x83)], might create problems in the event of array recovery through a live cdrom.<br><br>A new array will normally get a randomly assigned 128bit UUID which is very likely to be unique. If you have a specific need, you can choose a UUID for the array by giving the <b>--uuid=</b> option. Be warned that creating two arrays with the same UUID is a recipe for disaster. Also, using <b>--uuid=</b> when creating a v0.90 array will silently override any <b>--homehost=</b> setting.<br><br>When creating an array within a <b>CONTAINER</b> mdadm can be given either the list of devices to use, or simply the name of the container. The former case gives control over which devices in the container will be used for the array. The latter case allows mdadm to automatically choose which devices to use based on how much spare space is available.<br><br>The General Management options that are valid with <b>--create</b> are:--run <br><br>insist on running the array even if some devices look like they might be in use.--readonly start the array readonly - not supported yet. "},{"id": 18540,"commandid" : 2452,"title": "Manage Mode","page": " <br><br>Usage: <b>mdadm</b> device options... devices... <br> mdadm /dev/md0 -f /dev/hda1 -r /dev/hda1 -a /dev/hda1 will firstly mark /dev/hda1 as faulty in /dev/md0 and will then remove it from the array and finally add it back in as a spare. However only one md array can be affected by a single command. <br><br>When a device is added to an active array, mdadm checks to see if it has metadata on it which suggests that it was recently a member of the array. If it does, it tries to re-add the device. If there have been no changes since the device was removed, or if the array has a write-intent bitmap which has recorded whatever changes there were, then the device will immediately become a full member of the array and those differences recorded in the bitmap will be resolved. "},{"id": 18541,"commandid" : 2452,"title": "Misc Mode","page": " <br><br>Usage: <b>mdadm</b> options ... devices ... --query The device is examined to see if it is (1) an active md array, or (2) a component of an md array. The information discovered is reported.--detail The device should be an active md device. <b>mdadm</b> will display a detailed description of the array. <b>--brief</b> or <b>--scan</b> will cause the output to be less detailed and the format to be suitable for inclusion in <b>mdadm.conf</b>. The exit status of mdadm will normally be 0 unless mdadm failed to get useful information about the <b>device</b>(s); however, if the <b>--test</b> option is given, then the exit status will be:0 <p>The array is functioning normally. </p><p>1 </p><p>The array has at least one failed device. </p><p>2 </p><p>The array has multiple failed devices such that it is unusable. </p><p>4 </p><p>There was an error while trying to get information about the device. </p>--detail-platform Print detail of the platforms RAID capabilities (firmware / hardware topology). If the metadata is specified with <b>-e</b> or <b>--metadata=</b> then the return status will be:0 <p>metadata successfully enumerated its platform components on this system </p><p>1 </p><p>metadata is platform independent </p><p>2 </p><p>metadata failed to find its platform components on this system </p>--update-subarray= If the device is a container and the argument to --update-subarray specifies a subarray in the container, then attempt to update the given superblock field in the subarray. Similar to updating an array in assemble mode, the field to update is selected by <b>-U</b> or <b>--update=</b> option. Currently only <b>name</b> is supported. <p>The <b>name</b> option updates the subarray name in the metadata, it may not affect the device node name or the device node symlink until the subarray is re-assembled. If updating <b>name</b> would change the UUID of an active subarray this operation is blocked, and the command will end in an error. </p>--examine The device should be a component of an md array. mdadm will read the md superblock of the device and display the contents. If <b>--brief</b> or <b>--scan</b> is given, then multiple devices that are components of the one array are grouped together and reported in a single entry suitable for inclusion in <b>mdadm.conf</b>. <p>Having <b>--scan</b> without listing any devices will cause all devices listed in the config file to be examined. </p>--stop <br><br>The devices should be active md arrays which will be deactivated, as long as they are not currently in use.<br><br><b>--run</b><br><br>This will fully activate a partially assembled md array.--readonly This will mark an active array as read-only, providing that it is not currently being used.--readwrite This will change a <b>readonly</b> array back to being read/write.--scan <br><br>For all operations except <b>--examine</b>, <b>--scan</b> will cause the operation to be applied to all arrays listed in <b>/proc/mdstat</b>. For <b>--examine, --scan</b> causes all devices listed in the config file to be examined.-b, --brief Be less verbose. This is used with <b>--detail</b> and <b>--examine</b>. Using <b>--brief</b> with <b>--verbose</b> gives an intermediate level of verbosity. "},{"id": 18542,"commandid" : 2452,"title": "Monitor Mode","page": " <br><br>Usage: <b>mdadm --monitor</b> options... devices... <br><br>As well as reporting events, mdadm may move a spare drive from one array to another if they are in the same <b>spare-group</b> or <b>domain</b> and if the destination array has a failed drive but no spares.<br><br>If any devices are listed on the command line, mdadm will only monitor those devices. Otherwise all arrays listed in the configuration file will be monitored. Further, if <b>--scan</b> is given, then any other md devices that appear in <b>/proc/mdstat</b> will also be monitored.<br><br>The result of monitoring the arrays is the generation of events. These events are passed to a separate program (if specified) and may be mailed to a given E-mail address.<br><br>When passing events to a program, the program is run once for each event, and is given 2 or 3 command-line arguments: the first is the name of the event (see below), the second is the name of the md device which is affected, and the third is the name of a related device if relevant (such as a component device that has failed).<br><br>If <b>--scan</b> is given, then a program or an E-mail address must be specified on the command line or in the config file. If neither are available, then mdadm will not monitor anything. Without <b>--scan,</b> mdadm will continue monitoring as long as something was found to monitor. If no program or email is given, then each event is reported to <b>stdout</b>.<br><br>The different events are:<b>DeviceDisappeared</b>An md array which previously was configured appears to no longer be configured. (syslog priority: Critical) <p>If mdadm was told to monitor an array which is RAID0 or Linear, then it will report <b>DeviceDisappeared</b> with the extra information <b>Wrong-Level</b>. This is because RAID0 and Linear do not support the device-failed, hot-spare and resync operations which are monitored. </p><b>RebuildStarted</b>An md array started reconstruction. (syslog priority: Warning)<b>Rebuild</b>NNWhere NN is a two-digit number (ie. 05, 48). This indicates that rebuild has passed that many percent of the total. The events are generated with fixed increment since 0. Increment size may be specified with a commandline option (default is 20). (syslog priority: Warning)<b>RebuildFinished</b>An md array that was rebuilding, isnt any more, either because it finished normally or was aborted. (syslog priority: Warning)<b>Fail</b> <p>An active component device of an array has been marked as faulty. (syslog priority: Critical) </p><b>FailSpare</b>A spare component device which was being rebuilt to replace a faulty device has failed. (syslog priority: Critical)<b>SpareActive</b>A spare component device which was being rebuilt to replace a faulty device has been successfully rebuilt and has been made active. (syslog priority: Info)<b>NewArray</b>A new md array has been detected in the <b>/proc/mdstat</b> file. (syslog priority: Info)<b>DegradedArray</b>A newly noticed array appears to be degraded. This message is not generated when mdadm notices a drive failure which causes degradation, but only when mdadm notices that an array is degraded when it first sees the array. (syslog priority: Critical)<b>MoveSpare</b>A spare drive has been moved from one array in a <b>spare-group</b> or <b>domain</b> to another to allow a failed drive to be replaced. (syslog priority: Info)<b>SparesMissing</b>If mdadm has been told, via the config file, that an array should have a certain number of spare devices, and mdadm detects that it has fewer than this number when it first sees the array, it will report a <b>SparesMissing</b> message. (syslog priority: Warning)<b>TestMessage</b>An array was found at startup, and the <b>--test</b> flag was given. (syslog priority: Info)Only Fail, FailSpare, DegradedArray, SparesMissing and TestMessage cause Email to be sent. All events cause the program to be run. The program is run with two or three arguments: the event name, the array device and possibly a second device. <br><br>Each event has an associated array device (e.g. <b>/dev/md1</b>) and possibly a second device. For <b>Fail</b>, <b>FailSpare</b>, and <b>SpareActive</b> the second device is the relevant component device. For <b>MoveSpare</b> the second device is the array that the spare was moved from.<br><br>For mdadm to move spares from one array to another, the different arrays need to be labeled with the same <b>spare-group</b> or the spares must be allowed to migrate through matching POLICY domains in the configuration file. The <b>spare-group</b> name can be any string; it is only necessary that different spare groups use different names.<br><br>When mdadm detects that an array in a spare group has fewer active devices than necessary for the complete array, and has no spare devices, it will look for another array in the same spare group that has a full complement of working drive and a spare. It will then attempt to remove the spare from the second drive and add it to the first. If the removal succeeds but the adding fails, then it is added back to the original array.<br><br>If the spare group for a degraded array is not defined, mdadm will look at the rules of spare migration specified by POLICY lines in <b>mdadm.conf</b> and then follow similar steps as above if a matching spare is found. "},{"id": 18543,"commandid" : 2452,"title": "Grow Mode","page": " <br><br>The GROW mode is used for changing the size or shape of an active array. For this to work, the kernel must support the necessary change. Various types of growth are being added during 2.6 development.<br><br>Currently the supported changes include <br><br> increase or decrease the raid-devices attribute of RAID0, RAID1, RAID4, RAID5, and RAID6.<br><br> change the chunk-size and layout of RAID0, RAID4, RAID5 and RAID6.<br><br> convert between RAID1 and RAID5, between RAID5 and RAID6, between RAID0, RAID4, and RAID5, and between RAID0 and RAID10 (in the near-2 mode).<br><br> add a write-intent bitmap to any array which supports these bitmaps, or remove a write-intent bitmap from such an array.Using GROW on containers is currently supported only for Intels IMSM container format. The number of devices in a container can be increased - which affects all arrays in the container - or an array in a container can be converted between levels where those levels are supported by the container, and the conversion is on of those listed above. Resizing arrays in an IMSM container with --grow --size is not yet supported. <br><br>Grow functionality (e.g. expand a number of raid devices) for Intels IMSM container format has an experimental status. It is guarded by the <b>MDADM_EXPERIMENTAL</b> environment variable which must be set to 1 for a GROW command to succeed. This is for the following reasons:1. <br><br>Intels native IMSM check-pointing is not fully tested yet. This can causes IMSM incompatibility during the grow process: an array which is growing cannot roam between Microsoft <b>Windows</b>(R) and Linux systems.<br><br>2.<br><br>Interrupting a grow operation is not recommended, because it has not been fully tested for Intels IMSM container format yet.Note: Intels native checkpointing doesnt use --backup-file option and it is transparent for assembly feature. <br><br><b>SIZE CHANGES</b> <br><br>Note that when an array changes size, any filesystem that may be stored in the array will not automatically grow or shrink to use or vacate the space. The filesystem will need to be explicitly told to use the extra space after growing, or to reduce its size <b>prior</b> to shrinking the array.<br><br>Also the size of an array cannot be changed while it has an active bitmap. If an array has a bitmap, it must be removed before the size can be changed. Once the change is complete a new bitmap can be created. <br><br><b>RAID-DEVICES CHANGES</b> <br><br>When reducing the number of devices in a RAID1 array, the slots which are to be removed from the array must already be vacant. That is, the devices which were in those slots must be failed and removed.<br><br>When the number of devices is increased, any hot spares that are present will be activated immediately.<br><br>Changing the number of active devices in a RAID5 or RAID6 is much more effort. Every block in the array will need to be read and written back to a new location. From 2.6.17, the Linux Kernel is able to increase the number of devices in a RAID5 safely, including restarting an interrupted reshape. From 2.6.31, the Linux Kernel is able to increase or decrease the number of devices in a RAID5 or RAID6.<br><br>From 2.6.35, the Linux Kernel is able to convert a RAID0 in to a RAID4 or RAID5. mdadm uses this functionality and the ability to add devices to a RAID4 to allow devices to be added to a RAID0. When requested to do this, mdadm will convert the RAID0 to a RAID4, add the necessary disks and make the reshape happen, and then convert the RAID4 back to RAID0.<br><br>When decreasing the number of devices, the size of the array will also decrease. If there was data in the array, it could get destroyed and this is not reversible, so you should firstly shrink the filesystem on the array to fit within the new size. To help prevent accidents, mdadm requires that the size of the array be decreased first with <b>mdadm --grow --array-size</b>. This is a reversible change which simply makes the end of the array inaccessible. The integrity of any data can then be checked before the non-reversible reduction in the number of devices is request.<br><br>When relocating the first few stripes on a RAID5 or RAID6, it is not possible to keep the data on disk completely consistent and crash-proof. To provide the required safety, mdadm disables writes to the array while this critical section is reshaped, and takes a backup of the data that is in that section. For grows, this backup may be stored in any spare devices that the array has, however it can also be stored in a separate file specified with the <b>--backup-file</b> option, and is required to be specified for shrinks, RAID level changes and layout changes. If this option is used, and the system does crash during the critical period, the same file must be passed to <b>--assemble</b> to restore the backup and reassemble the array. When shrinking rather than growing the array, the reshape is done from the end towards the beginning, so the critical section is at the end of the reshape. <br><br><b>LEVEL CHANGES</b> --backup-file is required. If the array is not simultaneously being grown or shrunk, so that the array size will remain the same - for example, reshaping a 3-drive RAID5 into a 4-drive RAID6 - the backup file will be used not just for a cricital section but throughout the reshape operation, as described below under LAYOUT CHANGES. <br><br><b>CHUNK-SIZE AND LAYOUT CHANGES</b> --backup-file must be provided for these changes. Small sections of the array will be copied to the backup file while they are being rearranged. This means that all the data is copied twice, once to the backup and once to the new layout on the array, so this type of reshape will go very slowly. <br><br>If the reshape is interrupted for any reason, this backup file must be made available to <b>mdadm --assemble</b> so the array can be reassembled. Consequently the file cannot be stored on the device being reshaped. <br><br><b>BITMAP CHANGES</b> "},{"id": 18544,"commandid" : 2452,"title": "Incremental Mode","page": " <br><br>Usage: <b>mdadm --incremental</b> [<b>--run</b>] [<b>--quiet</b>] component-device mdadm --incremental --fail mdadm --incremental --rebuild-map mdadm --incremental --run --scan mdadm --incremental to be conditionally added to an appropriate array. <br><br>Conversely, it can also be used with the <b>--fail</b> flag to do just the opposite and find whatever array a particular device is part of and remove the device from that array.<br><br>If the device passed is a <b>CONTAINER</b> device created by a previous call to mdadm, then rather than trying to add that device to an array, all the arrays described by the metadata of the container will be started.<br><br>mdadm performs a number of tests to determine if the device is part of an array, and which array it should be part of. If an appropriate array is found, or can be created, mdadm adds the device to the array and conditionally starts the array.<br><br>Note that mdadm will normally only add devices to an array which were previously working (active or spare) parts of that array. The support for automatic inclusion of a new drive as a spare in some array requires a configuration through POLICY in config file.<br><br>The tests that mdadm makes are as follow:+ <br><br>Is the device permitted by <b>mdadm.conf</b>? That is, is it listed in a <b>DEVICES</b> line in that file. If <b>DEVICES</b> is absent then the default it to allow any device. Similar if <b>DEVICES</b> contains the special word <b>partitions</b> then any device is allowed. Otherwise the device name given to mdadm must match one of the names or patterns in a <b>DEVICES</b> line.<br><br>+<br><br>Does the device have a valid md superblock? If a specific metadata version is requested with <b>--metadata</b> or <b>-e</b> then only that style of metadata is accepted, otherwise mdadm finds any known version of metadata. If no md metadata is found, the device may be still added to an array as a spare if POLICY allows.mdadm/dev/md/md-device-map. If no array exists which matches the metadata on the new device, mdadm.conf or any name information stored in the metadata. If this name suggests a unit number, that number will be used, otherwise a free unit number will be chosen. Normally CREATE line in mdadm.conf suggests that a non-partitionable array is preferred, that will be honoured. <br><br>If the array is not found in the config file and its metadata does not identify it as belonging to the homehost, then mdadm will choose a name for the array which is certain not to conflict with any array which does belong to this host. It does this be adding an underscore and a small number to the name preferred by the metadata.<br><br>Once an appropriate array is found or created and the device is added, mdadm must decide if the array is ready to be started. It will normally compare the number of available (non-spare) devices to the number of devices that the metadata suggests need to be active. If there are at least that many, the array will be started. This means that if any devices are missing the array will not be restarted.<br><br>As an alternative, <b>--run</b> may be passed to mdadm in which case the array will be run as soon as there are enough devices present for the data to be accessible. For a RAID1, that means one device will start the array. For a clean RAID5, the array will be started as soon as all but one drive is present.<br><br>Note that neither of these approaches is really ideal. If it can be known that all device discovery has completed, then<b><br> mdadm -IRs</b><br> can be run which will try to start all arrays that are being incrementally assembled. They are started in read-auto mode in which they are read-only until the first write request. This means that no metadata updates are made and no attempt at resync or recovery happens. Further devices that are found before the first write can still be added safely. "},{"id": 18545,"commandid" : 2452,"title": "Environment","page": " <br><br>This section describes environment variables that affect how mdadm operates. MDADM_NO_MDMON Setting this value to 1 will prevent mdadm from automatically launching mdmon. This variable is intended primarily for debugging mdadm/mdmon.MDADM_NO_UDEV Normally, mdadm does not create any device nodes in /dev, but leaves that task to udev. If udev appears not to be configured, or if this environment variable is set to 1, the mdadm will create and devices that are needed. "},{"id": 18546,"commandid" : 2452,"title": "Examples","page": " <br><br><b>mdadm --query /dev/name-of-device</b><br> This will find out if a given device is a RAID array, or is part of one, and will provide brief information about the device.<br><br><b>mdadm --assemble --scan</b><br> This will assemble and start all arrays listed in the standard config file. This command will typically go in a system startup file.<br><br><b>mdadm --stop --scan</b><br> This will shut down all arrays that can be shut down (i.e. are not currently in use). This will typically go in a system shutdown script.<br><br><b>mdadm --follow --scan --delay=120</b><br> If (and only if) there is an Email address or program given in the standard config file, then monitor the status of all arrays listed in that file by polling them ever 2 minutes.<br><br><b>mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/hd[ac]1</b><br> Create /dev/md0 as a RAID1 array consisting of /dev/hda1 and /dev/hdc1.<br><br><b>echo DEVICE /dev/hd*[0-9] /dev/sd*[0-9] &gt; mdadm.conf<br> mdadm --detail --scan &gt;&gt; mdadm.conf</b><br> This will create a prototype config file that describes currently active arrays that are known to be made from partitions of IDE or SCSI drives. This file should be reviewed before being used as it may contain unwanted detail.<br><br><b>echo DEVICE /dev/hd[a-z] /dev/sd*[a-z] &gt; mdadm.conf<br> mdadm --examine --scan --config=mdadm.conf &gt;&gt; mdadm.conf</b><br> This will find arrays which could be assembled from existing IDE and SCSI whole drives (not partitions), and store the information in the format of a config file. This file is very likely to contain unwanted detail, particularly the <b>devices=</b> entries. It should be reviewed and edited before being used as an actual config file.<br><br><b>mdadm --examine --brief --scan --config=partitions<br> mdadm -Ebsc partitions</b><br> Create a list of devices by reading <b>/proc/partitions</b>, scan these for RAID superblocks, and printout a brief listing of all that were found.<br><br><b>mdadm -Ac partitions -m 0 /dev/md0</b><br> Scan all partitions and devices listed in <b>/proc/partitions</b> and assemble <b>/dev/md0</b> out of all such devices with a RAID superblock with a minor number of 0.<br><br><b>mdadm --monitor --scan --daemonise &gt; /run/mdadm/mon.pid</b><br> If config file contains a mail address or alert program, run mdadm in the background in monitor mode monitoring all md devices. Also write pid of mdadm daemon to <b>/run/mdadm/mon.pid</b>.<br><br><b>mdadm -Iq /dev/somedevice</b><br> Try to incorporate newly discovered device into some array as appropriate.<br><br><b>mdadm --incremental --rebuild-map --run --scan</b><br> Rebuild the array map from any current arrays, and then start any that can be started.<br><br><b>mdadm /dev/md4 --fail detached --remove detached</b><br> Any devices which are components of /dev/md4 will be marked as faulty and then remove from the array.<br><br><b>mdadm --grow /dev/md4 --level=6 --backup-file=/root/backup-md4</b><br> The array <b>/dev/md4</b> which is currently a RAID5 array will be converted to RAID6. There should normally already be a spare drive attached to the array as a RAID6 needs one more drive than a matching RAID5.<br><br><b>mdadm --create /dev/md/ddf --metadata=ddf --raid-disks 6 /dev/sd[a-f]</b><br> Create a DDF array over 6 devices.<br><br><b>mdadm --create /dev/md/home -n3 -l5 -z 30000000 /dev/md/ddf</b><br> Create a RAID5 array over any 3 devices in the given DDF set. Use only 30 gigabytes of each device.<br><br><b>mdadm -A /dev/md/ddf1 /dev/sd[a-f]</b><br> Assemble a pre-exist ddf array.<br><br><b>mdadm -I /dev/md/ddf1</b><br> Assemble all arrays contained in the ddf array, assigning names as appropriate.<br><br><b>mdadm --create --help</b><br> Provide help about the Create mode.<br><br><b>mdadm --config --help</b><br> Provide help about the format of the config file.<br><br><b>mdadm --help</b><br> Provide general help."},{"id": 18547,"commandid" : 2452,"title": "Files","page": " <br><br><b>/proc/mdstat</b> /proc filesystem, /proc/mdstat lists all active md devices with information about them. --scan is given in Misc mode, and to monitor array reconstruction on Monitor mode. <br><br><b>/etc/mdadm.conf</b> <a href=/man/5/mdadm.conf rel=nofollow>mdadm.conf</a>(5) for more details. <br><br><b>/dev/md/md-device-map</b> --incremental mode is used, this file gets a list of arrays currently being created. "},{"id": 18548,"commandid" : 2452,"title": "Device Names","page": " <br><br>mdadm understand two sorts of names for array devices.<br><br>The first is the so-called standard format name, which matches the names used by the kernel and which appear in /proc/mdstat.<br><br>The second sort can be freely chosen, but must reside in /dev/md/. When giving a device name to mdadm to create or assemble an array, either full path name such as /dev/md0 or /dev/md/home can be given, or just the suffix of the second sort of name, such as home can be given.<br><br>When mdadm chooses device names during auto-assembly or incremental assembly, it will sometimes add a small sequence number to the end of the name to avoid conflicted between multiple arrays that have the same name. If mdadm can reasonably determine that the array really is meant for this host, either by a hostname in the metadata, or by the presence of the array in <b>mdadm.conf</b>, then it will leave off the suffix if possible. Also if the homehost is specified as <b>&lt;ignore&gt;</b> mdadm will only use a suffix if a different array of the same name already exists or is listed in the config file.<br><br>The standard names for non-partitioned arrays (the only sort of md array available in 2.4 and earlier) are of the form /dev/mdNNwhere NN is a number. The standard names for partitionable arrays (as available from 2.6 onwards) are of the form /dev/md_dNNPartition numbers should be indicated by added pMM to these, thus /dev/md/d1p2. <br><br>From kernel version, 2.6.28 the non-partitioned array can actually be partitioned. So the md_dNN names are no longer needed, and partitions such as /dev/mdNNpXX are possible. "},{"id": 18549,"commandid" : 2452,"title": "Note","page": " <br><br>mdadm was previously known as mdctl.<br><br>mdadm is completely separate from the raidtools package, and does not use the /etc/raidtab configuration file at all."},{"id": 18550,"commandid" : 2452,"title": "See Also","page": " <br><br>For further information on mdadm usage, MD and the various levels of RAID, see: <b><a href=http://raid.wiki.kernel.org/>http://raid.wiki.kernel.org/</a></b>(based upon Jakob stergaards Software-RAID.HOWTO) <br><br>The latest version of mdadm should always be available from<b><a href=http://www.kernel.org/pub/linux/utils/raid/mdadm/>http://www.kernel.org/pub/linux/utils/raid/mdadm/</a></b>Related man pages: <br><br><b><a href=mdmon>mdmon</a></b>(8), <b><a href=/man/5/mdadm.conf rel=nofollow>mdadm.conf</a></b>(5), <b><a href=/man/4/md rel=nofollow>md</a></b>(4).<br><br><b>raidtab</b>(5), <b>raid0run</b>(8), <b>raidstop</b>(8), <b>mkraid</b>(8). "},{"id": 18551,"commandid" : 2452,"title": "Referenced By","page": " <a href=mdadm_selinux rel=nofollow>mdadm_selinux</a>(8), <a href=mdassemble rel=nofollow>mdassemble</a>(8), <a href=pvcreate rel=nofollow>pvcreate</a>(8) "},{"id": 18552,"commandid" : 2453,"title": "Name","page": " <br><br>mpicc - Compiles and links MPI programs written in C"},{"id": 18553,"commandid" : 2453,"title": "Description","page": " <br><br>This command can be used to compile and link MPI programs written in C. It provides the options and any special libraries that are needed to compile and link MPI programs.<br><br>It is important to use this command (or a Makefile processed with mpireconfig ) particularly when linking programs, as it provides the necessary libraries. It can also simplify the use of the MPE profiling libraries, through the use of the -mpilog , -mpitrace , and -mpianim commands."},{"id": 18554,"commandid" : 2453,"title": "Command Line Arguments","page": " <br><br><b>-mpilog</b> - Build version that generate MPE log files-mpitrace - Build version that generates traces-mpianim - Build version that generates real-time animation-show <br><br>- Show the commands that would be used without runnning them<br><br><b>-help</b><br><br>- Give short help<br><br><b>-echo</b><br><br>- Show exactly what this program is doing. This option should normally not be used.<br><br><b>others</b><br><br>- are passed to the compiler or linker. For example, -c causes files to be compiled, -g selects compilation with debugging on most systems, and -o name causes linking with the output executable given the name name . "},{"id": 18555,"commandid" : 2453,"title": "Environment Variables","page": " <br><br>The environment variables MPICH_CC and MPICH_CLINKER may be used to select different C compiler and linker. Note that since MPICH is built with a particular C and Fortran compiler, change the compilers used can cause problems. Use this only if you could intermix code compiled with the different compilers."},{"id": 18556,"commandid" : 2453,"title": "Examples","page": " <br><br>To compile a single file foo.c , usempicc"},{"id": 18557,"commandid" : 2453,"title": "See Also","page": " <br><br>mpif77, mpireconfig"},{"id": 18558,"commandid" : 2453,"title": "Location","page": " <br><br>/home/MPI/mansrc/commands <!-- google_ad_section_end -->"},{"id": 18559,"commandid" : 2453,"title": "Referenced By","page": " <a href=hcp rel=nofollow>hcp</a>(1), <a href=hf77 rel=nofollow>hf77</a>(1), <a href=/man/7/lam rel=nofollow>lam</a>(7), <a href=/man/5/lam-helpfile rel=nofollow>lam-helpfile</a>(5), <a href=/man/7/libmpi rel=nofollow>libmpi</a>(7), <a href=/man/7/mpi rel=nofollow>mpi</a>(7), <a href=opal_wrapper rel=nofollow>opal_wrapper</a>(1) "},{"id": 18560,"commandid" : 2454,"title": "Name","page": " <br><br>mpirun - Run mpi programs"},{"id": 18561,"commandid" : 2454,"title": "Description","page": " <br><br>mpirun is a shell script that attempts to hide the differences in starting jobs for various devices from the user. Mpirun attempts to determine what kind of machine it is running on and start the required number of jobs on that machine. On workstation clusters, if you are not using Chameleon, you must supply a file that lists the different machines that mpirun can use to run remote jobs or specify this file every time you run mpirun with the -machine file option. The default file is in util/machines/machines.&lt;arch&gt;.<br><br>mpirun typically works like thismpirun"},{"id": 18562,"commandid" : 2454,"title": "Parameters","page": " <br><br>The options for mpirun must come before the program you want to run and must be spelled out completely (no abreviations). Unrecognized options will be silently ignored.<br><br>mpirun [mpirun_options...] &lt;progname&gt; [options...] -arch &lt;architecture&gt; - specify the architecture (must have matching machines.&lt;arch&gt; file in ${MPIR_HOME}/util/machines) if using the execer-h <br><br>- This help-machine &lt;machine name&gt; - use startup procedure for &lt;machine name&gt;-machinefile &lt;machine-file name&gt; - Take the list of possible machines to run on from the file &lt;machine-file name&gt;-np &lt;np&gt; - specify the number of processors to run on-nolocal - do not run on the local machine (only works for p4 and ch_p4 jobs)-stdin filename - Use filename as the standard input for the program. This is needed for programs that must be run as batch jobs, such as some IBM SP systems and Intel Paragons using NQS (see -paragontype below).-t <br><br>- Testing - do not actually run, just print what would be executed<br><br><b>-v</b><br><br>- Verbose - throw in some comments<br><br><b>-dbx</b><br><br>- Start the first process under dbx where possible<br><br><b>-gdb</b><br><br>- Start the first process under gdb where possible (on the Meiko, selecting either -dbx or -gdb starts prun under totalview instead)<br><br><b>-xxgdb</b><br><br>- Start the first process under xxgdb where possible (-xdbx does not work)<br><br><b>-tv</b><br><br>- Start under totalview "},{"id": 18563,"commandid" : 2454,"title": "Special Options For Nec - Cenju-3","page": " -batch <br><br>- Excecute program as a batch job (using cjbr)-stdout filename - Use filename as the standard output for the program.-stderr filename - Use filename as the standard error for the program. "},{"id": 18564,"commandid" : 2454,"title": "Special Options For Nexus Device","page": " <br><br><b>-nexuspg filename</b> - Use the given Nexus startup file instead of creating one. Overrides -np and -nolocal, selects -leave_pg.-nexusdb filename - Use the given Nexus resource database. "},{"id": 18565,"commandid" : 2454,"title": "Special Options For Workstation Clusters","page": " -e <br><br>- Use execer to start the program on workstation clusters<br><br><b>-pg</b><br><br>- Use a procgroup file to start the p4 programs, not execer (default)-leave_pg - Do not delete the P4 procgroup file after running-p4pg filename - Use the given p4 procgroup file instead of creating one. Overrides -np and -nolocal, selects -leave_pg.-tcppg filename - Use the given tcp procgroup file instead of creating one. Overrides -np and -nolocal, selects -leave_pg.-p4ssport num - Use the p4 secure server with port number num to start the programs. If num is 0, use the value of the environment variable MPI_P4SSPORT. Using the server can speed up process startup. If MPI_USEP4SSPORT as well as MPI_P4SSPORT are set, then that has the effect of giving mpirun the -p4ssport 0 parameters. "},{"id": 18566,"commandid" : 2454,"title": "Special Options For Batch Environments","page": " <br><br><b>-mvhome</b> - Move the executable to the home directory. This is needed when all file systems are not cross-mounted. Currently only used by anlspx-mvback files - Move the indicated files back to the current directory. Needed only when using -mvhome; has no effect otherwise.-maxtime min - Maximum job run time in minutes. Currently used only by anlspx. Default value is 15 minutes-nopoll - Do not use a polling-mode communication. Available only on IBM SPx.-mem value - This is the per node memory request (in Mbytes). Needed for some CM-5s.-cpu time - This is the the hard cpu limit used for some CM-5s in minutes. "},{"id": 18567,"commandid" : 2454,"title": "Special Options For Ibm Sp2","page": " <br><br><b>-cac name</b> - CAC for ANL scheduler. Currently used only by anlspx. If not provided will choose some valid CAC. "},{"id": 18568,"commandid" : 2454,"title": "Special Options For Intel Paragon","page": " <br><br><b>-paragontype name</b> - Selects one of default, mkpart, NQS, depending on how you want to submit jobs to a Paragon.-paragonname name - Remote shells to name to run the job (using the -sz method) on a Paragon.-paragonpn name - Name of partition to run on in a Paragon (using the -pn name command-line argument) "},{"id": 18569,"commandid" : 2454,"title": "Return Value","page": " <br><br>On exit, mpirun returns a status of zero unless mpirun detected a problem, in which case it returns a non-zero status (currently, all are one, but this may change in the future)."},{"id": 18570,"commandid" : 2454,"title": "Specifying Heterogeneous Systems","page": " <br><br>Multiple architectures may be handled by giving multiple -arch and -np arguments. For example, to run a program on 2 sun4s and 3 rs6000s, with the local machine being a sun4, usempirunbefore specifying the number of processors. Also, the first not specified, then the first -arch must refer to the processor from which <br><br>(You must have machines.&lt;arch&gt; files for each arch that you use in the util/machines directory.)<br><br>Another approach that may be used the the ch_p4 device is to create a procgroup file directly. See the MPICH Users Guide for more information."},{"id": 18571,"commandid" : 2454,"title": "Location","page": " <br><br>/home/MPI/mansrc/commands <!-- google_ad_section_end -->"},{"id": 18572,"commandid" : 2454,"title": "Referenced By","page": " <a href=/man/5/appschema rel=nofollow>appschema</a>(5), <a href=/man/5/bhost rel=nofollow>bhost</a>(5), <a href=/man/7/lam rel=nofollow>lam</a>(7), <a href=/man/5/lam-helpfile rel=nofollow>lam-helpfile</a>(5), <a href=/man/2/lam_rfrmfd rel=nofollow>lam_rfrmfd</a>(2), <a href=lamboot rel=nofollow>lamboot</a>(1), <a href=lamexec rel=nofollow>lamexec</a>(1), <a href=laminfo rel=nofollow>laminfo</a>(1), <a href=/man/7/lamssi rel=nofollow>lamssi</a>(7), <a href=/man/7/lamssi_boot rel=nofollow>lamssi_boot</a>(7), <a href=/man/7/lamssi_coll rel=nofollow>lamssi_coll</a>(7), <a href=/man/7/lamssi_cr rel=nofollow>lamssi_cr</a>(7), <a href=/man/7/lamssi_rpi rel=nofollow>lamssi_rpi</a>(7), <a href=lamtrace rel=nofollow>lamtrace</a>(1), <a href=/man/7/libmpi rel=nofollow>libmpi</a>(7), <a href=loadgo rel=nofollow>loadgo</a>(1), <a href=/man/7/mpi rel=nofollow>mpi</a>(7), <a href=/man/3/mpi_comm_spawn rel=nofollow>mpi_comm_spawn</a>(3), <a href=/man/3/mpi_comm_spawn_multiple rel=nofollow>mpi_comm_spawn_multiple</a>(3), <a href=mpimsg rel=nofollow>mpimsg</a>(1), <a href=mpitask rel=nofollow>mpitask</a>(1) "},{"id": 18573,"commandid" : 2455,"title": "Name","page": " <br><br>orterun, mpirun, mpiexec - Execute serial and parallel jobs in Open MPI.<br><br><b>Note:</b> mpirun, mpiexec, and orterun are all synonyms for each other. Using any of the names will produce the same behavior."},{"id": 18574,"commandid" : 2455,"title": "Synopsis","page": " <br><br>Single Process Multiple Data (SPMD) Model:<br><br><b>mpirun</b> [ options ] <b>&lt;program&gt;</b> [ &lt;args&gt; ]<br><br>Multiple Instruction Multiple Data (MIMD) Model:<br><br><b>mpirun</b> [ global_options ] [ local_options1 ] <b>&lt;program1&gt;</b> [ &lt;args1&gt; ] : [ local_options2 ] <b>&lt;program2&gt;</b> [ &lt;args2&gt; ] : ... : [ local_optionsN ] <b>&lt;programN&gt;</b> [ &lt;argsN&gt; ]<br><br>Note that in both models, invoking mpirun via an absolute path name is equivalent to specifying the --prefix option with a &lt;dir&gt; value equivalent to the directory where mpirun resides, minus its last subdirectory. For example:<br><br><b>%</b> /usr/local/bin/mpirun ...<br><br>is equivalent to<br><br><b>%</b> mpirun --prefix /usr/local"},{"id": 18575,"commandid" : 2455,"title": "Quick Summary","page": " <br><br>If you are simply looking for how to run an MPI application, you probably want to use a command line of the following form:<br><br><b>%</b> mpirun [ -np X ] [ --hostfile &lt;filename&gt; ] &lt;program&gt;<br><br>This will run X copies of &lt;program&gt; in your current run-time environment (if running under a supported resource manager, Open MPIs mpirun will usually automatically use the corresponding resource manager process starter, as opposed to, for example, rsh or ssh, which require the use of a hostfile, or will default to running all X copies on the localhost), scheduling (by default) in a round-robin fashion by CPU slot. See the rest of this page for more details."},{"id": 18576,"commandid" : 2455,"title": "Options","page": " <br><br>mpirun will send the name of the directory where it was invoked on the local node to each of the remote nodes, and attempt to change to that directory. See the Current Working Directory section below for further details. &lt;program&gt; <br><br>The program executable. This is identified as the first non-recognized argument to mpirun.<br><br><b>&lt;args&gt;</b><br><br>Pass these run-time arguments to every new process. These must always be the last arguments to mpirun. If an app context file is used, &lt;args&gt; will be ignored.-h, --help Display help for this command-q, --quiet Suppress informative messages from orterun during application execution.-v, --verbose Be verbose-V, --version Print version number. If no other arguments are given, this will also cause orterun to exit.To specify which hosts (nodes) of the cluster to run on: -H, -host, --host <host1,host2,...,hostN> List of hosts on which to invoke processes.-hostfile, --hostfile <hostfile> Provide a hostfile to use.-machinefile, --machinefile <machinefile> Synonym for -hostfile.To specify the number of processes to launch: -c, -n, --n, -np <#> Run this many copies of the program on the given nodes. This option indicates that the specified file is an executable program and not an application context. If no value is provided for the number of copies to execute (i.e., neither the -np nor its synonyms are provided on the command line), Open MPI will automatically execute a copy of the program on each process slot (see below for description of a process slot). This feature, however, can only be used in the SPMD model and will return an error (without beginning execution of the application) otherwise.-npersocket, --npersocket &lt;#persocket&gt; On each node, launch this many processes times the number of processor sockets on the node. The -npersocket option also turns on the -bind-to-socket option.-npernode, --npernode &lt;#pernode&gt; On each node, launch this many processes.-pernode, --pernode On each node, launch one process -- equivalent to -npernode 1.To map processes to nodes: -loadbalance, --loadbalance Uniform distribution of ranks across all nodes. See more detailed description below.-nolocal, --nolocal Do not run any copies of the launched application on the same node as orterun is running. This option will override listing the localhost with <b>--host</b> or any other host-specifying mechanism.-nooversubscribe, --nooversubscribe Do not oversubscribe any nodes; error (without starting any processes) if the requested number of processes would cause oversubscription. This option implicitly sets max_slots equal to the slots value for each node.-bynode, --bynode Launch processes one per node, cycling by node in a round-robin fashion. This spreads processes evenly among nodes and assigns ranks in a round-robin, by node manner.For process binding: -bycore, --bycore Associate processes with successive cores if used with one of the -bind-to-* options.-bysocket, --bysocket Associate processes with successive processor sockets if used with one of the -bind-to-* options.-cpus-per-proc, --cpus-per-proc &lt;#perproc&gt; Use the number of cores per process if used with one of the -bind-to-* options.-cpus-per-rank, --cpus-per-rank &lt;#perrank&gt; Alias for -cpus-per-proc.-bind-to-core, --bind-to-core Bind processes to cores.-bind-to-socket, --bind-to-socket Bind processes to processor sockets.-bind-to-none, --bind-to-none Do not bind processes. (Default.)-report-bindings, --report-bindings Report any bindings for launched processes.-slot-list, --slot-list &lt;slots&gt; List of processor IDs to be used for binding MPI processes. The specified bindings will be applied to all MPI processes. See explanation below for syntax.For rankfiles: -rf, --rankfile &lt;rankfile&gt; Provide a rankfile file.To manage standard I/O: -output-filename, --output-filename <filename> Redirect the stdout, stderr, and stddiag of all ranks to a rank-unique version of the specified filename. Any directories in the filename will automatically be created. Each output file will consist of filename.rank, where the rank will be left-filled with zeros for correct ordering in listings.-stdin, --stdin &lt;rank&gt; The MPI rank that is to receive stdin. The default is to forward stdin to rank=0, but this option can be used to forward stdin to any rank. It is also acceptable to specify none, indicating that no ranks are to receive stdin.-tag-output, --tag-output Tag each line of output to stdout, stderr, and stddiag with <b>[jobid, rank]&lt;stdxxx&gt;</b> indicating the process jobid and rank that generated the output, and the channel which generated it.-timestamp-output, --timestamp-output Timestamp each line of output to stdout, stderr, and stddiag.-xml, --xml Provide all output to stdout, stderr, and stddiag in an xml format.-xterm, --xterm <ranks> Display the specified ranks in separate xterm windows. The ranks are specified as a comma-separated list of ranges, with a -1 indicating all. A separate window will be created for each specified rank. <b>Note:</b> In some environments, xterm may require that the executable be in the users path, or be specified in absolute or relative terms. Thus, it may be necessary to specify a local executable as ./foo instead of just foo. If xterm fails to find the executable, mpirun will hang, but still respond correctly to a ctrl-c. If this happens, please check that the executable is being specified correctly and try again.To manage files and runtime environment: -path, --path <path> &lt;path&gt; that will be used when attempting to locate the requested executables. This is used prior to using the local PATH setting.--prefix <dir> Prefix directory that will be used to set the PATH and LD_LIBRARY_PATH on the remote node before invoking Open MPI or the target process. See the Remote Execution section, below.--preload-binary Copy the specified <b>executable</b>(s) to remote machines prior to starting remote processes. The executables will be copied to the Open MPI session directory and will be deleted upon completion of the job.--preload-files &lt;files&gt; Preload the comma separated list of files to the current working directory of the remote machines where processes will be launched prior to starting those processes.--preload-files-dest-dir &lt;path&gt; The destination directory to be used for preload-files, if other than the current working directory. By default, the absolute and relative paths provided by --preload-files are used.--tmpdir <dir> Set the root for the session directory tree for mpirun only.-wd <dir> Synonym for -wdir.-wdir <dir> Change to the directory &lt;dir&gt; before the users program executes. See the Current Working Directory section for notes on relative paths. <b>Note:</b> If the -wdir option appears both on the command line and in an application context, the context will take precedence over the command line.-x <env> Export the specified environment variables to the remote nodes before executing the program. Only one environment variable can be specified per -x option. Existing environment variables can be specified or new variable names specified with corresponding values. For example: <b>%</b> mpirun -x DISPLAY -x OFILE=/tmp/out ... <p>The parser for the -x option is not very sophisticated; it does not even understand quoted values. Users are advised to set variables in the environment, and then use -x to export (not define) them. </p>Setting MCA parameters: -gmca, --gmca <key> <value> Pass global MCA parameters that are applicable to all contexts. &lt;key&gt; is the parameter name; &lt;value&gt; is the parameter value.-mca, --mca &lt;key&gt; &lt;value&gt; Send arguments to various MCA modules. See the MCA section, below.For debugging: -debug, --debug Invoke the user-level debugger indicated by the orte_base_user_debugger MCA parameter.-debugger, --debugger Sequence of debuggers to search for when --debug is used (i.e. a synonym for orte_base_user_debugger MCA parameter).-tv, --tv Launch processes under the TotalView debugger. Deprecated backwards compatibility flag. Synonym for --debug.There are also other options: -aborted, --aborted <#> Set the maximum number of aborted processes to display.--app <appfile> Provide an appfile, ignoring all other command line options.-cf, --cartofile <cartofile> Provide a cartography file.--hetero Indicates that multiple app_contexts are being provided that are a mix of 32/64-bit binaries.-leave-session-attached, --leave-session-attached Do not detach OmpiRTE daemons used by this application. This allows error messages from the daemons as well as the underlying environment (e.g., when failing to launch a daemon) to be output.-ompi-server, --ompi-server &lt;uri or file&gt; Specify the URI of the Open MPI server, or the name of the file (specified as file:filename) that contains that info. The Open MPI server is used to support multi-application data exchange via the MPI-2 MPI_Publish_name and MPI_Lookup_name functions.-wait-for-server, --wait-for-server Pause mpirun before launching the job until ompi-server is detected. This is useful in scripts where ompi-server may be started in the background, followed immediately by an mpirun command that wishes to connect to it. Mpirun will pause until either the specified ompi-server is contacted or the server-wait-time is exceeded.-server-wait-time, --server-wait-time &lt;secs&gt; The max amount of time (in seconds) mpirun should wait for the ompi-server to start. The default is 10 seconds.The following options are useful for developers; they are not generally useful to most ORTE and/or MPI users: -d, --debug-devel Enable debugging of the OmpiRTE (the run-time layer in Open MPI). This is not generally useful for most users.--debug-daemons Enable debugging of any OmpiRTE daemons used by this application.--debug-daemons-file Enable debugging of any OmpiRTE daemons used by this application, storing output in files.-launch-agent, --launch-agent Name of the executable that is to be used to start processes on the remote nodes. The default is orted. This option can be used to test new daemon concepts, or to pass options back to the daemons without having mpirun itself see them. For example, specifying a launch agent of orted -mca odls_base_verbose 5 allows the developer to ask the orted for debugging output without clutter from mpirun itself.--noprefix Disable the automatic --prefix behaviorThere may be other options listed with "},{"id": 18577,"commandid" : 2455,"title": "Description","page": " <br><br>One invocation of mpirun starts an MPI application running under Open MPI. If the application is single process multiple data (SPMD), the application can be specified on the mpirun command line.<br><br>If the application is multiple instruction multiple data (MIMD), comprising of multiple programs, the set of programs and argument can be specified in one of two ways: Extended Command Line Arguments, and Application Context.<br><br>An application context describes the MIMD program set including all arguments in a separate file. This file essentially contains multiple mpirun command lines, less the command name itself. The ability to specify different options for different instantiations of a program is another reason to use an application context.<br><br>Extended command line arguments allow for the description of the application layout on the command line using colons (:) to separate the specification of programs and arguments. Some options are globally set across all specified programs (e.g. --hostfile), while others are specific to a single program (e.g. -np).<br><br><b>Specifying Host Nodes</b> <br><br>For example,mpirun -H aa,aa,bb ./a.out launches two processes on node aa and one on bb.Or, consider the hostfile <br><br><b>%</b> cat myhostfile aa slots=2 bb slots=2 cc slots=2<br><br>Here, we list both the host names (aa, bb, and cc) but also how many slots there are for each. Slots indicate how many processes can potentially execute on a node. For best performance, the number of slots may be chosen to be the number of cores on the node or the number of processor sockets. If the hostfile does not provide slots information, a default of 1 is assumed. When running under resource managers (e.g., SLURM, Torque, etc.), Open MPI will obtain both the hostnames and the number of slots directly from the resource manger.mpirun -hostfile myhostfile ./a.out will launch two processes on each of the three nodes.mpirun -hostfile myhostfile -host aa ./a.out will launch two processes, both on node aa.mpirun -hostfile myhostfile -host dd ./a.out will find no hosts to run on and abort with an error. That is, the specified host dd is not in the specified hostfile. <br><br><b>Specifying Number of Processes</b> <br><br>The number of processes launched can be specified as a multiple of the number of nodes or processor sockets available. For example,mpirun -H aa,bb -npersocket 2 ./a.out launches processes 0-3 on node aa and process 4-7 on node bb, where aa and bb are both dual-socket nodes. The -npersocket option also turns on the -bind-to-socket option, which is discussed in a later section.mpirun -H aa,bb -npernode 2 ./a.out launches processes 0-1 on node aa and processes 2-3 on node bb.mpirun -H aa,bb -npernode 1 ./a.out launches one process per host node.mpirun -H aa,bb -pernode ./a.out is the same as -npernode 1.Another alternative is to specify the number of processes with the <br><br><b>%</b> cat myhostfile aa slots=4 bb slots=4 cc slots=4<br><br>Now,mpirun -hostfile myhostfile -np 6 ./a.out will launch ranks 0-3 on node aa and ranks 4-5 on node bb. The remaining slots in the hostfile will not be used since the -np option indicated that only 6 processes should be launched. <br><br><b>Mapping Processes to Nodes</b> <br><br>node aa node bb node cc<br><br>mpirun 0 1 2 3 4 5<br><br>mpirun -loadbalance 0 1 2 3 4 5<br><br>mpirun -bynode 0 3 1 4 2 5<br><br>mpirun -nolocal 0 1 2 3 4 5<br><br>The -loadbalance option tries to spread processes out fairly among the nodes.<br><br>The -bynode option does likewise but numbers the processes in by node in a round-robin fashion.<br><br>The -nolocal option prevents any processes from being mapped onto the local host (in this case node aa). While mpirun typically consumes few system resources, -nolocal can be helpful for launching very large jobs where mpirun may actually need to use noticable amounts of memory and/or processing time.<br><br>Just as -np can specify fewer processes than there are slots, it can also oversubscribe the slots. For example, with the same hostfile:mpirun -hostfile myhostfile -np 14 ./a.out will launch processes 0-3 on node aa, 4-7 on bb, and 8-11 on cc. It will then add the remaining two processes to whichever nodes it chooses.One can also specify limits to oversubscription. For example, with the same hostfile: will produce an error since -nooversubscribe prevents oversubscription.Limits to oversubscription can also be specified in the hostfile itself: % cat myhostfile aa slots=4 max_slots=4 bb max_slots=4 cc slots=4 <br><br>The max_slots field specifies such a limit. When it does, the slots value defaults to the limit. Now:mpirun -hostfile myhostfile -np 14 ./a.out causes the first 12 processes to be launched as before, but the remaining two processes will be forced onto node cc. The other two nodes are protected by the hostfile against oversubscription by this job.Using the <br><br>Of course, -np can also be used with the -H or -host option. For example,mpirun -H aa,bb -np 8 ./a.out launches 8 processes. Since only two hosts are specified, after the first two processes are mapped, one to aa and one to bb, the remaining processes oversubscribe the specified hosts.And here is a MIMD example: will launch process 0 running hostname on node aa and processes 1 and 2 each running uptime on nodes bb and cc, respectively. <br><br><b>Process Binding</b> <br><br>To bind processes, one must first associate them with the resources on which they should run. For example, the -bycore option associates the processes on a node with successive cores. Or, -bysocket associates the processes with successive processor sockets, cycling through the sockets in a round-robin fashion if necessary. And -cpus-per-proc indicates how many cores to bind per process.<br><br>But, such association is meaningless unless the processes are actually bound to those resources. The binding option specifies the granularity of binding -- say, with -bind-to-core or -bind-to-socket. One can also turn binding off with -bind-to-none, which is typically the default.<br><br>Finally, -report-bindings can be used to report bindings.<br><br>As an example, consider a node with two processor sockets, each comprising four cores. We run mpirun with -np 4 -report-bindings and the following additional options:<br><br>% mpirun ... -bycore -bind-to-core [...] ... binding child [...,0] to cpus 0001 [...] ... binding child [...,1] to cpus 0002 [...] ... binding child [...,2] to cpus 0004 [...] ... binding child [...,3] to cpus 0008<br><br>% mpirun ... -bysocket -bind-to-socket [...] ... binding child [...,0] to socket 0 cpus 000f [...] ... binding child [...,1] to socket 1 cpus 00f0 [...] ... binding child [...,2] to socket 0 cpus 000f [...] ... binding child [...,3] to socket 1 cpus 00f0<br><br>% mpirun ... -cpus-per-proc 2 -bind-to-core [...] ... binding child [...,0] to cpus 0003 [...] ... binding child [...,1] to cpus 000c [...] ... binding child [...,2] to cpus 0030 [...] ... binding child [...,3] to cpus 00c0<br><br>% mpirun ... -bind-to-none<br><br>Here, -report-bindings shows the binding of each process as a mask. In the first case, the processes bind to successive cores as indicated by the masks 0001, 0002, 0004, and 0008. In the second case, processes bind to all cores on successive sockets as indicated by the masks 000f and 00f0. The processes cycle through the processor sockets in a round-robin fashion as many times as are needed. In the third case, the masks show us that 2 cores have been bind per process. In the fourth case, binding is turned off and no bindings are reported.<br><br>Open MPIs support for process binding depends on the underlying operating system. Therefore, processing binding may not be available on every system.<br><br>Process binding can also be set with MCA parameters. Their usage is less convenient than that of mpirun options. On the other hand, MCA parameters can be set not only on the mpirun command line, but alternatively in a system or user mca-params.conf file or as environment variables, as described in the MCA section below. The correspondences are:<br><br>mpirun option MCA parameter key value<br><br>-bycore rmaps_base_schedule_policy core -bysocket rmaps_base_schedule_policy socket -bind-to-core orte_process_binding core -bind-to-socket orte_process_binding socket -bind-to-none orte_process_binding none<br><br>The orte_process_binding value can also take on the :if-avail attribute. This attribute means that processes will be bound only if this is supported on the underlying operating system. Without the attribute, if there is no such support, the binding request results in an error. For example, you could have<br><br>% cat $HOME/.openmpi/mca-params.conf rmaps_base_schedule_policy = socket orte_process_binding = socket:if-avail <br><br><b>Rankfiles</b> <br><br>cat myrankfile rank 0=aa slot=1:0-2 rank 1=bb slot=0:0,1 rank 2=cc slot=1-2 mpirun -H aa,bb,cc,dd -rf myrankfile ./a.out So that<br><br>Rank 0 runs on node aa, bound to socket 1, cores 0-2. Rank 1 runs on node bb, bound to socket 0, cores 0 and 1. Rank 2 runs on node cc, bound to cores 1 and 2. <br><br><b>Application Context or Executable Program?</b> <br><br><b>Locating Files</b> node(s). <br><br>If a relative directory is specified, it must be relative to the initial working directory determined by the specific starter used. For example when using the rsh or ssh starters, the initial directory is $HOME by default. Other starters may set the initial directory to the current working directory from the invocation of mpirun. <br><br><b>Current Working Directory</b> <br><br>If the -wdir option appears both in a context file and on the command line, the context file directory will override the command line value.<br><br>If the -wdir option is specified, Open MPI will attempt to change to the specified directory on all of the remote nodes. If this fails, mpirun will abort.<br><br>If the -wdir option is <b>not</b> specified, Open MPI will send the directory name where mpirun was invoked to each of the remote nodes. The remote nodes will try to change to that directory. If they are unable (e.g., if the directory does not exit on that node), then Open MPI will use the default directory determined by the starter.<br><br>All directory changing occurs before the users program is invoked; it does not wait until MPI_INIT is called. <br><br><b>Standard I/O</b> Note: The node that invoked <br><br>Open MPI directs UNIX standard output and error from remote nodes to the node that invoked mpirun and prints it on the standard output/error of mpirun. Local processes inherit the standard output/error of mpirun and transfer to it directly.<br><br>Thus it is possible to redirect standard I/O for Open MPI applications by using the typical shell redirection procedure on mpirun.<br><br><b>%</b> mpirun -np 2 my_app &lt; my_input &gt; my_output<br><br>Note that in this example only the MPI_COMM_WORLD rank 0 process will receive the stream from my_input on stdin. The stdin on all the other nodes will be tied to /dev/null. However, the stdout from all nodes will be collected into the my_output file. <br><br><b>Signal Propagation</b> <br><br>SIGUSR1 and SIGUSR2 signals received by orterun are propagated to all processes in the job.<br><br>One can turn on forwarding of SIGSTOP and SIGCONT to the program executed by mpirun by setting the MCA parameter orte_forward_job_control to 1. A SIGTSTOP signal to mpirun will then cause a SIGSTOP signal to be sent to all of the programs started by mpirun and likewise a SIGCONT signal to mpirun will cause a SIGCONT sent.<br><br>Other signals are not currently propagated by orterun. <br><br><b>Process Termination / Signal Handling</b> <br><br>User signal handlers should probably avoid trying to cleanup MPI state (Open MPI is, currently, neither thread-safe nor async-signal-safe). For example, if a segmentation fault occurs in MPI_SEND (perhaps because a bad buffer was passed in) and a user signal handler is invoked, if this user handler attempts to invoke MPI_FINALIZE, Bad Things could happen since Open MPI was already in MPI when the error occurred. Since mpirun will notice that the process died due to a signal, it is probably not necessary (and safest) for the user to only clean up non-MPI state. <br><br><b>Process Environment</b> <br><br>See the Remote Execution section for more details. <br><br><b>Remote Execution</b> <br><br>However, it is not always desirable or possible to edit shell startup files to set PATH and/or LD_LIBRARY_PATH. The --prefix option is provided for some simple configurations where this is not possible.<br><br>The --prefix option takes a single argument: the base directory on the remote node where Open MPI is installed. Open MPI will use this directory to set the remote PATH and LD_LIBRARY_PATH before executing any Open MPI or user applications. This allows running Open MPI jobs without having pre-configured the PATH and LD_LIBRARY_PATH on the remote nodes.<br><br>Open MPI adds the basename of the current nodes bindir (the directory where Open MPIs executables are installed) to the prefix and uses that to set the PATH on the remote node. Similarly, Open MPI adds the basename of the current nodes libdir (the directory where Open MPIs libraries are installed) to the prefix and uses that to set the LD_LIBRARY_PATH on the remote node. For example:Local bindir: <br><br>/local/node/directory/bin<br><br>Local libdir:<br><br>/local/node/directory/lib64If the following command line is used: <br><br><b>%</b> mpirun --prefix /remote/node/directory<br><br>Open MPI will add /remote/node/directory/bin to the PATH and /remote/node/directory/lib64 to the D_LIBRARY_PATH on the remote node before attempting to execute anything.<br><br>Note that --prefix can be set on a per-context basis, allowing for different values for different nodes.<br><br>The --prefix option is not sufficient if the installation paths on the remote node are different than the local node (e.g., if /lib is used on the local node, but /lib64 is used on the remote node), or if the installation paths are something other than a subdirectory under a common prefix.<br><br>Note that executing mpirun via an absolute pathname is equivalent to specifying --prefix without the last subdirectory in the absolute pathname to mpirun. For example:<br><br><b>%</b> /usr/local/bin/mpirun ...<br><br>is equivalent to<br><br><b>%</b> mpirun --prefix /usr/local <br><br><b>Exported Environment Variables</b> <br><br><b>Setting MCA Parameters</b> <br><br>The -mca switch takes two arguments: &lt;key&gt; and &lt;value&gt;. The &lt;key&gt; argument generally specifies which MCA module will receive the value. For example, the &lt;key&gt; btl is used to select which BTL to be used for transporting MPI messages. The &lt;value&gt; argument is the value that is passed. For example:mpirun -mca btl tcp,self -np 1 foo Tells Open MPI to use the tcp and self BTLs, and to run a single copy of foo an allocated node.mpirun -mca btl self -np 1 foo Tells Open MPI to use the self BTL, and to run a single copy of foo an allocated node.The <br><br>Note that the -mca switch is simply a shortcut for setting environment variables. The same effect may be accomplished by setting corresponding environment variables before running mpirun. The form of the environment variables that Open MPI sets is:<br><br>OMPI_MCA_&lt;key&gt;=&lt;value&gt;<br><br>Thus, the -mca switch overrides any previously set environment variables. The -mca settings similarly override MCA parameters set in the $OPAL_PREFIX/etc/openmpi-mca-params.conf or $HOME/.openmpi/mca-params.conf file.<br><br>Unknown &lt;key&gt; arguments are still set as environment variable -- they are not checked (by mpirun) for correctness. Illegal or incorrect &lt;value&gt; arguments may or may not be reported -- it depends on the specific MCA module.<br><br>To find the available component types under the MCA architecture, or to find the available parameters for a specific component, use the ompi_info command. See the <b><a href=ompi_info>ompi_info</a></b>(1) man page for detailed information on the command. "},{"id": 18578,"commandid" : 2455,"title": "Examples","page": " <br><br>Be sure also to see the examples throughout the sections above. Run 4 copies of prog1 using the ib, tcp, and self BTLs for the transport of MPI messages.mpirun -np 4 -mca btl tcp,sm,self --mca btl_tcp_if_include ce0 prog1<br> Run 4 copies of prog1 using the tcp, sm and self BTLs for the transport of MPI messages, with TCP using only the ce0 interface to communicate. Note that other BTLs have similar if_include MCA parameters. "},{"id": 18579,"commandid" : 2455,"title": "Return Value","page": " <br><br>mpirun returns 0 if all ranks started by mpirun exit after calling MPI_FINALIZE. A non-zero value is returned if an internal error occurred in mpirun, or one or more ranks exited before calling MPI_FINALIZE. If an internal error occurred in mpirun, the corresponding error code is returned. In the event that one or more ranks exit before calling MPI_FINALIZE, the return value of the rank of the process that mpirun first notices died before calling MPI_FINALIZE will be returned. Note that, in general, this will be the first rank that died but is not guaranteed to be so. <!-- google_ad_section_end --> "},{"id": 18580,"commandid" : 2456,"title": "Name","page": " "},{"id": 18581,"commandid" : 2456,"title": "Synopsis","page": " aireplay-ng [options] <replay interface> "},{"id": 18582,"commandid" : 2456,"title": "Description","page": " aireplay-ng injects specially generated ARP-request packets into an existing wireless network in order to generate traffic. By sending these ARP-request packets again and again, the target host will respond with encrypted replies, thus providing new and possibly weak IVs.<br><br><b>aireplay-ng</b> supports single-NIC injection/monitor.<br> This feature needs driver patching.<br>"},{"id": 18583,"commandid" : 2456,"title": "Options","page": " Shows the help screen.Filter options: MAC address of access point.-dMAC address of destination.-sMAC address of source.-mMinimum packet length.-nMaximum packet length.-uFrame control, type field.-vFrame control, subtype field.-tFrame control, To DS bit.-fFrame control, From DS bit.-wFrame control, WEP bit.Replay options: Number of packets per second.-pSet frame control word (hex).-aSet Access Point MAC address.-cSet destination MAC address.-hSet source MAC address.-eSet target SSID for Fake Authentication attack (see below).-jARP Replay attack : inject FromDS pakets (see below).-gSet ring buffer size (rbsize must be higher or equal to 1 ).-kSet destination IP in fragments.-lSet source IP in fragments.-oSet the number of packets for every authentication and association attempt.-qSet the time between keep-alive packets in fake authentication mode.-ySpecifies the keystream file for fake shared key authentication.Source options: Capture packets from this interface.-rExtract packets from this pcap file.Attack modes: Deauthenticate stations.-1Fake authentication with AP.-2,Interactive frame selection.-3,Standard ARP-request replay.-4,Decrypt/chopchop WEP packet.-5,Generates a valid keystream.-9,Tests injection and quality. "},{"id": 18584,"commandid" : 2456,"title": "Fragmentation Versus Chopchop","page": " <br><br><b>Fragmentation:</b> <br> - Can obtain the full packet length of 1500 bytes XOR. This means you can subsequently pretty well create any size of packet.<br> - May work where chopchop does not<br> - Is extremely fast. It yields the XOR stream extremely quickly when successful.Cons<br> - Setup to execute the attack is more subject to the device drivers. For example, Atheros does not generate the correct packets unless the wireless card is set to the mac address you are spoofing.<br> - You need to be physically closer to the access point since if any packets are lost then the attack fails. <br><br><b>Chopchop</b> <br> - May work where frag does not work.Cons<br> - Cannot be used against every access point.<br> - The maximum XOR bits is limited to the length of the packet you chopchop against.<br> - Much slower then the fragmentation attack.<br> "},{"id": 18585,"commandid" : 2456,"title": "Author","page": " This manual page was written by Adam Cecile <gandalf@le-vert.net> for the Debian system (but may be used by others). Permission is granted to copy, distribute and/or modify this document under the terms of the GNU General Public License, Version 2 or any later version published by the Free Software Foundation On Debian systems, the complete text of the GNU General Public License can be found in /usr/share/common-licenses/GPL. "},{"id": 18586,"commandid" : 2456,"title": "See Also","page": " <b><a href=airmon-ng>airmon-ng</a></b>(1) <b><a href=airdecap-ng>airdecap-ng</a></b>(1) <b><a href=aircrack-ng>aircrack-ng</a></b>(1) <b><a href=airodump-ng>airodump-ng</a></b>(1) <b><a href=airtun-ng>airtun-ng</a></b>(1) <b><a href=packetforge-ng>packetforge-ng</a></b>(1) <b><a href=ivstools>ivstools</a></b>(1) <b><a href=kstats>kstats</a></b>(1) <b><a href=makeivs>makeivs</a></b>(1) "},{"id": 18587,"commandid" : 2457,"title": "Name","page": " <br><br>byobu - wrapper script for seeding a users byobu configuration and launching a text based window manager (either screen or tmux)"},{"id": 18588,"commandid" : 2457,"title": "Synopsis","page": " <br><br><b>byobu</b> [screen options]<br><br><b>byobu-screen</b> [screen options]<br><br><b>byobu-tmux</b> [tmux options]<br><br>Options to <b>byobu</b> are simply passed through <b><a href=screen>screen</a></b>(1) or <b><a href=tmux rel=nofollow>tmux</a></b>(1)."},{"id": 18589,"commandid" : 2457,"title": "Description","page": " <br><br><b>byobu</b> is a script that launches a text based window manager (either <b><a href=screen rel=nofollow>screen</a></b>(1) or <b><a href=tmux rel=nofollow>tmux</a></b>(1)) in the byobu configuration. This enables the display of system information and status notifications within two lines at the bottom of the screen session. It also enables multiple tabbed terminal sessions, accessible through simple keystrokes.<br><br><b>byobu</b> currently defaults to using <b><a href=tmux rel=nofollow>tmux</a></b>(1) (if present) as the backend, however, this can be overriden with the <b><a href=byobu-select-backend rel=nofollow>byobu-select-backend</a></b>(1) utility.<br><br>Note that BYOBU_CONFIG_DIR=$XDG_CONFIG_HOME/byobu if defined, and $HOME/.byobu otherwise."},{"id": 18590,"commandid" : 2457,"title": "Background Colors","page": " <br><br>The background colors of the <b>byobu</b> status lines can be adjusted by editing the files $HOME/.byobu/color (for <b>byobu-screen</b>) and $HOME/.byobu/color.tmux (for <b>byobu-tmux</b>). The command <b>Ctrl-Shift-F5</b> will change the background to a randomly selected color when running in <b>byobu-tmux</b> mode. Simply remove those files to return to the default color configuration."},{"id": 18591,"commandid" : 2457,"title": "Status Notifications","page": " <br><br><b>byobu</b> supports a number of unique and interesting status notifications across the lowest two lines in the screen. Each status notification item is independently configurable, enabled and disabled by the configuration utility. The guide below helps identify each status item (in alphabetical order):<br><br><b>apport</b> - symbol displayed if there are pending crash reports; {!} symbol displayed on the lower bar toward the left, in black on an orange background<br><br><b>arch</b> - system architecture; displayed on the lower bar toward the left, in the default text color on the default background color<br><br><b>battery</b> - battery information; display on the lower bar toward the right; - indicates discharging, + indicates charging, = indicates fully charged; when charging or discharging, the current battery capacity as a percentage is displayed; the colours green, yellow, and red are used to give further indication of the batterys charge state; you may override the detected battery by setting BATTERY=/proc/acpi/battery/BAT0 in $BYOBU_CONFIG_DIR/statusrc<br><br><b>cpu_count</b> - the number of cpus or cores on the system; displayed in the lower bar toward the right in the default text color on the default background, followed by a trailing x<br><br><b>cpu_freq</b> - the current frequency of the cpu in GHz; displayed in the lower bar toward the right in white text on a light blue background<br><br><b>cpu_temp</b> - the cpu temperature in Celsius (default) or Fahrenheit, configure TEMP=F or TEMP=C in $BYOBU_CONFIG_DIR/statusrc; displayed in the lower bar toward the right in yellow text on a black background; you may override the detected cpu temperature device by setting MONITORED_TEMP=/proc/acpi/whatever in $BYOBU_CONFIG_DIR/statusrc<br><br><b>custom</b> - user defined custom scripts; must be executable programs of any kind in $BYOBU_CONFIG_DIR/bin; must be named N_NAME, where N is the frequency in seconds to refresh the status indicator, and NAME is the name of the script; N should not be less than 5 seconds; the script should echo a small amount of text to standard out, standard error is discarded; the indicator will be displayed in the lower panel, in inverted colors to your current background/foreground scheme, unless you manually specify the colors in your scripts output; BEWARE, cpu-intensive custom scripts may impact your overall system performance and could upset your system administrator! Example: $BYOBU_CONFIG_DIR/bin/1000_uname #!/bin/sh printf \\005{= bw}%s\\005{-} $(uname -r)<br><br><b>date</b> - the system date in YYYY-MM-DD formate; displayed in the lower on the far right in the default text color on the default background<br><br><b>disk</b> - total disk space available and total used on / directory; displayed in the lower bar on the far right in white text on a light purple background; override the default directory by specifying an alternate mount point with MONITORED_DISK=/wherever in $BYOBU_CONFIG_DIR/statusrc<br><br><b>disk_io</b> - instantaneous read/write througput in kB/s or MB/s over the last 3 seconds; displayed in the lower bar toward the right in white text on a light purple background with a leading &lt; sign indicating read speed and &gt; sign indicating write speed; override the default monitored disk by specifying an alternate device with MONITORED_DISK=/dev/sdb, and override the default DISK_IO_THRESHOLD=50 (kB/s) in $BYOBU_CONFIG_DIR/statusrc<br><br><b>distro</b> - OS/distribution name of the release running on the current system as reported by <b><b><a href=lsb_release>lsb_release</a></b>(1)</b> or /etc/issue; displayed in the lower bar in bold black text toward the left on a grey background; you may override the detected release with DISTRO=Whatever in $BYOBU_CONFIG_DIR/statusrc<br><br><b>ec2_cost</b> - an estimation of the cost of the current boot of the system in terms of the Amazon EC2 billing model; displayed in the lower bar toward the right in green text on a black background; there is a leading ~ to indicate that this is an estimation, and the monetary units are US Dollars $; if not running in EC2, this plugin is disabled unless EC2_ESTIMATE=1 in ~/.byobu/statusrc<br><br><b>entropy</b> - a count of the systems current entropy in bytes; displayed in the lower bar toward the right in yellow text on a dark grey background; there is a leading e to indicate entropy<br><br><b>raid</b> - note very prominently if there is a RAID failure detected, in red blinking text on a white background; the term RAID notes that there is something wrong with the RAID, and if there is a rebuild/resync in progress, the percent complete is also shown<br><br><b>rcs_cost</b> - an estimation of the cost of the current boot of the system in terms of the Rackspace Cloud Server billing model; displayed in the lower bar toward the right in green text on a black background; there is a leading ~ to indicate that this is an estimation, and the monetary units are US Dollars $<br><br><b>fan_speed</b> - cpu or system fan speed as reported by lm-sensors; displayed in the lower bar toward the right in black text on a grey background; there is a trailing rpm for units; you may override the detected fan by setting FAN=/sys/path/to/your/fan1_input in $BYOBU_CONFIG_DIR/statusrc<br><br><b>hostname</b> - the hostname of the system; displayed in the upper bar on the far right in bold black text on a grey background; there is a leading @ symbol if the username status is also enabled<br><br><b>ip_address</b> - the IPv4 address of the system in dotted decimal form; displayed in the upper bar on the far right in bold black text on a grey background; you can override and display your IPv6 address by setting IPV6=1, and you can show your external ip address by setting IP_EXTERNAL=1 in $BYOBU_CONFIG_DIR/statusrc<br><br><b>ip_address4</b> - the IPv4 address of the system in dotted decimal form; displayed in the upper bar on the far right in bold black text on a grey background; you can show your external ip address by setting IP_EXTERNAL=1 in $BYOBU_CONFIG_DIR/statusrc<br><br><b>ip_address6</b> - the IPv6 address of the system; displayed in the upper bar on the far right in bold black text on a grey background; you can show your external ip address by setting IP_EXTERNAL=1 in $BYOBU_CONFIG_DIR/statusrc<br><br><b>load_average</b> - the system load average over the last 1 minute; displayed in the lower bar toward the right in black text on a yellow background<br><br><b>logo</b> - an approximation of the current operating systems logo; displayed in the lower bar on the far left; you may customize this logo by setting a chosen logo in $BYOBU_CONFIG_DIR/logo, or you may override this with LOGO=:-D in $BYOBU_CONFIG_DIR/statusrc<br><br><b>mail</b> - system mail for the current user; the letter [M] is displayed in the lower bar toward the left in black text on a grey background<br><br><b>memory</b> - total memory available and used in the system; displayed in the lower bar toward the right in white text on a green background<br><br><b>menu</b> - a simple indicator directing new users to use the F9 keybinding to access the byobu menu<br><br><b>network</b> - instantaneous upload/download bandwidth in [GMk]bps over the last 3 seconds; nothing is displayed if traffic is 0; displayed in the lower bar toward the left in white text on a purple background with a leading ^ sign indicating up and v sign indicating down; override the default interface by specifying an alternate interface with MONITORED_NETWORK=eth1, and override the default units (bits) with NETWORK_UNITS=bytes, and override the default NETWORK_THRESHOLD=20 (kbps) in $BYOBU_CONFIG_DIR/statusrc<br><br><b>notify_osd</b> - Send on-screen notification messages to screens notification buffer<br><br><b>processes</b> - total number of processes running on the system; displayed in the lower bar in white text on a dark yellow background with a trailing &amp; indicating background processes<br><br><b>reboot_required</b> - symbol present if a reboot is required following a system update; displayed in the lower bar white text on a blue background by the symbol (R); additionally, reboot_required will print &lt;F5&gt; in white text on a blue background, if Byobu requires you to reload your profile to affect some changes; it will also detect if your system is currently in <b>powernap</b>(8) state and if so print .zZ.<br><br><b>release</b> - OS/distribution name of the release running on the current system as reported by <b><b><a href=lsb_release rel=nofollow>lsb_release</a></b>(1)</b> or /etc/issue; displayed in the lower bar in bold black text toward the left on a grey background; you may override the detected release with RELEASE=Whatever in $BYOBU_CONFIG_DIR/statusrc; you may also abbreviate the release string to N characters by setting RELEASE_ABBREVIATED=N in $BYOBU_CONFIG_DIR/statusrc<br><br><b>services</b> - users can configure a list of services to monitor, define the SERVICES variable in $BYOBU_CONFIG_DIR/statusrc, a whitespace separated of services, each service should include the init name of the service, then a pipe, and then an abbreviated name or symbol to display when running (e.g. SERVICES=ssh|ssh apache2|http); displayed in the lower bar toward the center in cyan on a white background<br><br><b>swap</b> - total swap space and total used as a percentage of the total available; displayed in the lower bar toward the right in white text on a light green background with a trailing % sign<br><br><b>time</b> - the system time in HH:MM:SS format; displayed in the lower bar on the far right in the default text and default background colors<br><br><b>time_binary</b> - only for the hard core geek, the local system time in binary; requires UTF-8 support in a VERY recent version of GNU Screen; displayed in the lower bar on the far right in the default text and background colors<br><br><b>time_utc</b> - the UTC system time in HH:MMformat; displayed in the lower bar on the far right in dark text on a light background<br><br><b>updates_available</b> - the number of updates available on the system; displayed in the lower bar toward the right in white text on a red background with a trailing ! sign; if any updates are marked security updates, then there will be a total of two trailing exclamation points, !!<br><br><b>uptime</b> - the total system uptime since last boot; displayed in the lower bar toward the right in blue text on a grey background<br><br><b>users</b> - the number of remote users logged into the system via sshd, empty if 0 users; displayed in the lower bar toward the right in red text on a grey background with a trailing # sign; set USERS_DISTINCT=1 to instead count the number of distinct users logged into the system (rather than open ssh sessions)<br><br><b>whoami</b> - the name of the user who owns the screen session; displayed in the upper bar toward the far right in bold black text on a grey background<br><br><b>wifi_quality</b> - the connection rate and signal quality of the wifi connection; displayed in the lower bar toward the right in black text on a cyan background; the connection rate is in Mb/s and the signal quality is as a percentage with a trailing %; override the default interface by specifying an alternate interface with MONITORED_NETWORK=wlan0 in $BYOBU_CONFIG_DIR/statusrc"},{"id": 18592,"commandid" : 2457,"title": "Sessions","page": " <br><br>Byobu name screen sessions byobu, if unspecified. To hide sessions from <b><a href=byobu-select-session>byobu-select-session</a></b>(1), prepend a . to the beginning of the session name, like:<br><br>byobu -S .hidden"},{"id": 18593,"commandid" : 2457,"title": "Windows","page": " <br><br>Each open window in the screen session is displayed in the upper bar toward the far left. These are numbered, and include indicators as to activity in the window (see activity in <b><a href=screen rel=nofollow>screen</a></b>(1) for symbol definitions). The current active window is highlighted by inverting the background/text from the rest of the window bar.<br><br>Users can create a list of windows to launch at startup in $BYOBU_CONFIG_DIR/windows. This file is the same syntax as ~/.screenrc, each line specifying a window using the screen command, as described in <b><a href=screen rel=nofollow>screen</a></b>(1).<br><br>User can also launch Byobu with unique window sets. Users can store these as $BYOBU_CONFIG_DIR/windows.[NAME], and launch Byobu with the environment variable <b>BYOBU_WINDOWS</b>.<br><br>For example: $ cat $BYOBU_CONFIG_DIR/windows.ssh_sessions screen -t localhost bash screen -t aussie ssh root@aussie screen -t beagle ssh root@beagle screen -t collie ssh root@collie $ BYOBU_WINDOWS=ssh_sessions byobu"},{"id": 18594,"commandid" : 2457,"title": "Units Of Measure","page": " <br><br>byobu uses binary for capacity measurements of KB, MB, GB, and TB. This means multiples of 1024 rather than multiples of 1000, in accordance with JEDEC Standard 100B.01 for disk and memory capacity measurements. See: * <a href=http://en.wikipedia.org/wiki/JEDEC_memory_standards>http://en.wikipedia.org/wiki/JEDEC_memory_standards</a><br><br>byobu uses decimal for measurements of network data transfer, meaning multiple of 1000, rather than 1024. See: * <a href=http://en.wikipedia.org/wiki/Data_rate_units>http://en.wikipedia.org/wiki/Data_rate_units</a>"},{"id": 18595,"commandid" : 2457,"title": "Keybindings","page": " <br><br>byobu keybindings can be user defined in /usr/share/byobu/keybindings/ (or within .screenrc if byobu-export was used). The common key bindings are:<br><br><b>F2</b> - Create a new window<br><br><b>F3</b> - Move to previous window<br><br><b>F4</b> - Move to next window<br><br><b>F5</b> - Reload profile<br><br><b>F6</b> - Detach from this session<br><br><b>F7</b> - Enter copy/scrollback mode<br><br><b>F8</b> - Re-title a window<br><br><b>F9</b> - Configuration Menu<br><br><b>F12</b> - Lock this terminal<br><br><b>shift-F2</b> - Split the screen horizontally<br><br><b>ctrl-F2</b> - Split the screen vertically<br><br><b>shift-F3</b> - Shift the focus to the previous split region<br><br><b>shift-F4</b> - Shift the focus to the next split region<br><br><b>shift-F5</b> - Join all splits<br><br><b>ctrl-F6</b> - Remove this split<br><br><b>ctrl-F5</b> - Reconnect GPG and SSH sockets<br><br><b>shift-F6</b> - Detach, but do not logout<br><br><b>alt-pgup</b> - Enter scrollback mode<br><br><b>alt-pgdn</b> - Enter scrollback mode<br><br><b>Ctrl-a $</b> - show detailed status<br><br><b>Ctrl-a R</b> - Reload profile<br><br><b>Ctrl-a !</b> - Toggle key bindings on and off<br><br><b>Ctrl-a k</b> - Kill the current window<br><br><b>Ctrl-a ~</b> - Save the current windows scrollback buffer"},{"id": 18596,"commandid" : 2457,"title": "SCROLLBACK, COPY, PASTE MODES","page": " <br><br>Each window in Byobu has up to 10,000 lines of scrollback history, which you can enter and navigate using the <b>alt-pgup</b> and <b>alt-pgdn</b> keys. Exit this scrollback mode by hitting <b>enter</b>. You can also easily copy and paste text from scrollback mode. To do so, enter scrollback using <b>alt-pgup</b> or <b>alt-pgdn</b>, press the <b>spacebar</b> to start highlighting text, use <b>up/down/left/right/pgup/pgdn</b> to select the text, and press <b>enter</b> to copy the text. You can then paste the text using <b>alt-insert</b> or <b>ctrl-a-]</b>."},{"id": 18597,"commandid" : 2457,"title": "Bugs","page": " <br><br>For Byobu colors to work properly, older versions of GNU Screen require a 1-line patch to adjust MAX_WINMSG_REND in screen.c. The change is in GNU Screens upstream source control system as of 2010-01-26, but GNU Screen has not released a new upstream version in several years. You can disable colors entirely by setting MONOCHROME=1 in $BYOBU_CONFIG_DIR/statusrc. For more information, see: * <a href=http://savannah.gnu.org/bugs/?22146>http://savannah.gnu.org/bugs/?22146</a><br><br>PuTTY users have reported that the F2, F3, and F4 shortcut keys are not working properly. PuTTY sends the same escape sequences as the linux console for F1-F4 by default. You can fix this problem in the PuTTY config, Terminal -&gt; Keyboard -&gt; Function keys: Xterm R6. See: <a href=http://www.mail-archive.com/screen-users@gnu.org/msg01525.html>http://www.mail-archive.com/screen-users@gnu.org/msg01525.html</a><br><br>Apple Mac OSX terminal users have reported flashing text. You can fix this in the advanced settings of the terminal application, with Declare Terminal As: xterm-color.<br><br>Apple Mac keyboard users may need to specify a vt100 terminal by adding this to your OSX profile, in order to get Byobus function keys and colors to work: alias ssh=TERM=vt100 ssh<br><br>Users of a non-UTF-8 locale (such as cs_CZ charset ISO-8859-2), may need to add defutf8 off to ~/.screenrc, if some characters are rendering as ?.<br><br>Users who customize their PS1 prompt need to put this setting in ~/.bashrc, rather than ~/.profile, in order for it to work correctly with Byobu.<br><br>If you run <b>byobu</b>(1) under <b><a href=/man/8/sudo>sudo</a></b>(8), you <b>must</b> use the -H option, such that the users $HOME directory environment variable is set properly. Otherwise, <b>byobu</b>(1) will create a bunch of directories in the $SUDO_USERs $HOME, but will be owned by root. To prevent this from happening, <b>byobu</b>(1) will simply refuse to run if $USER does not own $HOME.<br><br>Byobu requires a suitable <b><a href=/man/3/ulimit>ulimit</a></b>(3) values to run. If you get an error at startup saying, pipe: too many open files, then check your ulimit -a values, as your open files or max user processes are too low. In this case, you will probably need to run simple <b><a href=screen rel=nofollow>screen</a></b>(1)"},{"id": 18598,"commandid" : 2457,"title": "See Also","page": " <br><br><b><a href=screen rel=nofollow>screen</a></b>(1), <b><a href=byobu-config>byobu-config</a></b>(1), <b><a href=byobu-export>byobu-export</a></b>(1), <b><a href=byobu-status>byobu-status</a></b>(1), <b><b><a href=byobu-status-detail>byobu-status-detail</a></b>(1), <b><a href=byobu-enable>byobu-enable</a></b>(1), <b><a href=byobu-launch>byobu-launch</a></b>(1), <b><a href=byobu-select-backend>byobu-select-backend</a></b>(1), <b><a href=tmux>tmux</a></b>(1)</b> http://launchpad.net/byobu "},{"id": 18599,"commandid" : 2457,"title": "Author","page": " <br><br>This manpage and the utility were written by Dustin Kirkland &lt;<a href=mailto:kirkland@ubuntu.com>kirkland@ubuntu.com</a>&gt; for Ubuntu systems (but may be used by others). Permission is granted to copy, distribute and/or modify this document and the utility under the terms of the GNU General Public License, Version 3 published by the Free Software Foundation.<br><br>The complete text of the GNU General Public License can be found in /usr/share/common-licenses/GPL on Debian/Ubuntu systems, or in /usr/share/doc/fedora-release-*/GPL on Fedora systems, or on the web at <a href=http://www.gnu.org/licenses/gpl.txt>http://www.gnu.org/licenses/gpl.txt</a>. <!-- google_ad_section_end -->"},{"id": 18600,"commandid" : 2457,"title": "Referenced By","page": " <a href=byobu-launcher-install rel=nofollow>byobu-launcher-install</a>(1), <a href=byobu-launcher-uninstall rel=nofollow>byobu-launcher-uninstall</a>(1), <a href=byobu-layout rel=nofollow>byobu-layout</a>(1), <a href=byobu-screen rel=nofollow>byobu-screen</a>(1), <a href=byobu-select-profile rel=nofollow>byobu-select-profile</a>(1), <a href=byobu-tmux rel=nofollow>byobu-tmux</a>(1) "},{"id": 18601,"commandid" : 2458,"title": "Name","page": " <br><br>encfs - mounts or creates an encrypted virtual filesystem"},{"id": 18602,"commandid" : 2458,"title": "Synopsis","page": " <br><br><b>encfs</b> [<b>--version</b>] [<b>-s</b>] [<b>-f</b>] [<b>-v</b><b>--verbose</b>] [<b>-i MINUTES</b> <b>--idle=MINUTES</b>] [<b>--extpass=program</b>] [<b>-S</b><b>--stdinpass</b>] [<b>--anykey</b>] [<b>--forcedecode</b>] [<b>-d</b><b>--fuse-debug</b>] [<b>--public</b>] [<b>--no-default-flags</b>] [<b>--ondemand</b>] [<b>--reverse</b>] [<b>--standard</b>] [<b>-o FUSE_OPTION</b> ] rootdir mountPoint [<b>--</b> [Fuse Mount Options]]"},{"id": 18603,"commandid" : 2458,"title": "Description","page": " <br><br><b>EncFS</b> creates a virtual encrypted filesystem which stores encrypted data in the rootdir directory and makes the unencrypted data visible at the mountPoint directory. The user must supply a password which is used to (indirectly) encrypt both filenames and file contents.<br><br>If <b>EncFS</b> is unable to find a supported filesystem at the specified rootdir, then the user will be asked if they wish to create a new encrypted filesystem at the specified location. Options will be presented to the user allowing some control over the algorithms to use. As <b>EncFS</b> matures, there may be an increasing number of choices."},{"id": 18604,"commandid" : 2458,"title": "Options","page": " <br><br><b>-i</b>, <b>--idle=MINUTES</b> Enable automatic unmount of the filesystem after a period of inactivity. The period is specified in minutes, so the shortest timeout period that can be requested is one minute. <b>EncFS</b> will not automatically unmount if there are files open within the filesystem, even if they are open in read-only mode. However simply having files open does not count as activity.-f <br><br>The <b>-f</b> (foreground) option causes <b>EncFS</b> to run in the foreground. Normally <b>EncFS</b> spawns off as a daemon and runs in the background, returning control to the spawning shell. With the <b>-f</b> option, it will run in the foreground and any warning/debug log messages will be displayed on standard error. In the default (background) mode, all log messages are logged via syslog.-v, --verbose Causes <b>EncFS</b> to enable logging of various debug channels within <b>EncFS</b>. Normally these logging messages are disabled and have no effect. It is recommended that you run in foreground (<b>-f</b>) mode when running with verbose enabled.-s <br><br>The <b>-s</b> (single threaded) option causes <b>EncFS</b> to run in single threaded mode. By default, <b>EncFS</b> runs in multi-threaded mode. This option is used during <b>EncFS</b> development in order to simplify debugging and allow it to run under memory checking tools..-d, --fuse-debug Enables debugging within the <b>FUSE</b> library. This should only be used if you suspect a problem within <b>FUSE</b> itself (not <b>EncFS</b>), as it generates a lot of low-level data and is not likely to be very helpful in general problem tracking. Try verbose mode (<b>-v</b>) first, which gives a higher level view of what is happening within <b>EncFS</b>.--forcedecode This option only has an effect on filesystems which use MAC block headers. By default, if a block is decoded and the stored MAC doesnt match what is calculated, then an IO error is returned to the application and the block is not returned. However, by specifying <b>--forcedecode</b>, only an error will be logged and the data will still be returned to the application. This may be useful for attempting to read corrupted files.--public Attempt to make encfs behave as a typical multi-user filesystem. By default, all FUSE based filesystems are visible only to the user who mounted them. No other users (including root) can view the filesystem contents. The <b>--public</b> option does two things. It adds the FUSE flags allow_other and default_permission when mounting the filesystem, which tells FUSE to allow other users to access the filesystem, and to use the ownership permissions provided by the filesystem. Secondly, the <b>--public</b> flag changes how encfss node creation functions work - as they will try and set ownership of new nodes based on the caller identification. <p><b>Warning</b>: In order for this to work, encfs must be run as root -- otherwise it will not have the ability to change ownership of files. I recommend that you instead investigate if the fuse allow_other option can be used to do what you want before considering the use of <b>--public</b>. </p>--ondemand Mount the filesystem on-demand. This currently only makes sense in combination with <b>--idle</b> and <b>--extpass</b> options. When the filesystem becomes idle, instead of exiting, <b>EncFS</b> stops allowing access to the filesystem by internally dropping its reference to it. If someone attempts to access the filesystem again, the extpass program is used to prompt the user for the password. If this succeeds, then the filesystem becomes available again.--reverse Normally <b>EncFS</b> provides a plaintext view of data on demand. Normally it stores enciphered data and displays plaintext data. With <b>--reverse</b> it takes as source plaintext data and produces enciphered data on-demand. This can be useful for creating remote encrypted backups, where you do not wish to keep the local files unencrypted. <p>For example, the following would create an encrypted view in /tmp/crypt-view. </p>encfs --reverse /home/me /tmp/crypt-viewYou could then copy the /tmp/crypt-view directory in order to have a copy of the encrypted data. You must also keep a copy of the file /home/me/.encfs5 which contains the filesystem information. Together, the two can be used to reproduce the unencrypted data: ENCFS5_CONFIG=/home/me/.encfs5 encfs /tmp/crypt-view /tmp/plain-viewNow /tmp/plain-view contains the same data as /home/me <p>Note that <b>--reverse</b> mode only works with limited configuration options, so many settings may be disabled when used. </p>--standard If creating a new filesystem, this automatically selects standard configuration options, to help with automatic filesystem creation. This is the set of options that should be used unless you know what youre doing and have read the documentation. <p>When not creating a filesystem, this flag does nothing. </p>-o FUSE_ARG Pass through <b>FUSE</b> args to the underlying library. This makes it easy to pass FUSE options when mounting <b>EncFS</b> via mount (and /etc/fstab). Eg: mount encfs#/home/me-crypt /home/me -t fuse -o kernel_cacheNote that encfs arguments cannot be set this way. If you need to set encfs arguments, create a wrapper, such as encfs-reverse; #!/bin/sh encfs --reverse $*Then mount using the script path mount encfs-reverse#/home/me /home/me-crypt -t fuse-- <br><br>The <b>--</b> option tells <b>EncFS</b> to send any remaining arguments directly to <b>FUSE</b> . In turn, <b>FUSE</b> passes the arguments to <b>fusermount</b>. See the <b>fusermount</b> help page for information on available commands.--no-default-flags <b>Encfs</b> adds the FUSE flags use_ino and default_permissions by default, as of version 1.2.2, because that improves compatibility with some programs.. If for some reason you need to disable one or both of these flags, use the option <b>--no-default-flags</b>. <p>The following command lines produce the same result: </p>encfs raw crypt encfs --no-default-flags raw crypt -- -o use_ino,default_permissions--extpass=program Specify an external program to use for getting the user password. When the external program is spawned, the environment variable RootDir will be set to contain the path to the root directory. The program should print the password to standard output. <p><b>EncFS</b> takes everything returned from the program to be the password, except for a trailing newline (\n) which will be removed. </p><p>For example, specifying <b>--extpass</b>=/usr/lib/ssh/ssh-askpass will cause <b>EncFS</b> to use sshs password prompt program. </p><p><b>Note</b>: <b>EncFS</b> reads at most 2k of data from the password program, and it removes any trailing newline. Versions before 1.4.x accepted only 64 bytes of text. </p>-S, --stdinpass Read password from standard input, without prompting. This may be useful for scripting encfs mounts. <p>Note that you should make sure the filesystem and mount points exist first. Otherwise encfs will prompt for the filesystem creation options, which may interfere with your script. </p>--anykey Turn off key validation checking. This allows <b>EncFS</b> to be used with secondary passwords. This could be used to store a separate set of files in an encrypted filesystem. <b>EncFS</b> ignores files which do not decode properly, so files created with separate passwords will only be visible when the filesystem is mounted with their associated password. <p>Note that if the primary password is changed (using <b>encfsctl</b>), the other passwords will not be usable unless the primary password is set back to what it was, as the other passwords rely on an invalid decoding of the volume key, which will not remain the same if the primary password is changed. </p><p><b>Warning</b>: Use this option at your own risk. </p> "},{"id": 18605,"commandid" : 2458,"title": "Examples","page": " <br><br>Create a new encrypted filesystem. Store the raw (encrypted) data in ~/.crypt , and make the unencrypted data visible in ~/crypt. Both directories are in the home directory in this example. This example shows the full output of encfs as it asks the user if they wish to create the filesystem:% -u (unmount) option: "},{"id": 18606,"commandid" : 2458,"title": "Caveats","page": " <br><br><b>EncFS</b> is not a true filesystem. It does not deal with any of the actual storage or maintenance of files. It simply translates requests (encrypting or decrypting as necessary) and passes the requests through to the underlying host filesystem. Therefor any limitations of the host filesystem will likely be inherited by <b>EncFS</b> (or possibly be further limited).<br><br>One such limitation is filename length. If your underlying filesystem limits you to N characters in a filename, then <b>EncFS</b> will limit you to approximately 3*(N-2)/4. For example if the host filesystem limits to 256 characters, then <b>EncFS</b> will be limited to 190 character filenames. This is because encrypted filenames are always longer then plaintext filenames."},{"id": 18607,"commandid" : 2458,"title": "Filesystem Options","page": " <br><br>When <b>EncFS</b> is given a root directory which does not contain an existing <b>EncFS</b> filesystem, it will give the option to create one. Note that options can only be set at filesystem creation time. There is no support for modifying a filesystems options in-place.<br><br>If you want to upgrade a filesystem to use newer features, then you need to create a new filesystem and mount both the old filesystem and new filesystem at the same time and copy the old to the new.<br><br>Multiple instances of encfs can be run at the same time, including different versions of encfs, as long as they are compatible with the current FUSE module on your system.<br><br>A choice is provided for two pre-configured settings (standard and paranoia), along with an expert configuration mode.<br><br>Standard mode uses the following settings: Cipher: AES Key Size: 192 bits PBKDF2 with 1/2 second runtime, 160 bit salt Filesystem Block Size: 1024 bytes Filename Encoding: Block encoding with IV chaining Unique initialization vector file headers<br><br>Paranoia mode uses the following settings: Cipher: AES Key Size: 256 bits PBKDF2 with 3 second runtime, 160 bit salt Filesystem Block Size: 1024 bytes Filename Encoding: Block encoding with IV chaining Unique initialization vector file headers Message Authentication Code block headers External IV Chaining<br><br>In the expert / manual configuration mode, each of the above options is configurable. Here is a list of current options with some notes about what they mean:"},{"id": 18608,"commandid" : 2458,"title": "Key Derivation Function","page": " <br><br>As of version 1.5, <b>EncFS</b> now uses PBKDF2 as the default key derivation function. The number of iterations in the keying function is selected based on wall clock time to generate the key. In standard mode, a target time of 0.5 seconds is used, and in paranoia mode a target of 3.0 seconds is used.<br><br>On a 1.6Ghz AMD 64 system, it rougly 64k iterations of the key derivation function can be handled in half a second. The exact number of iterations to use is stored in the configuration file, as it is needed to remount the filesystem.<br><br>If an <b>EncFS</b> filesystem configuration from 1.4.x is modified with version 1.5 (such as when using encfsctl to change the password), then the new PBKDF2 function will be used and the filesystem will no longer be readable by older versions. Which encryption algorithm to use. The list is generated automatically based on what supported algorithms <b>EncFS</b> found in the encryption libraries. When using a recent version of <b>OpenSSL</b>, Blowfish and AES are the typical options. <p>Blowfish is an 8 byte cipher - encoding 8 bytes at a time. AES is a 16 byte cipher. </p>Cipher Key SizeMany, if not all, of the supported ciphers support multiple key lengths. There is not really much need to have enormous key lengths. Even 160 bits (the default) is probably overkill.Filesystem Block SizeThis is the size (in bytes) that <b>EncFS</b> deals with at one time. Each block gets its own initialization vector and is encoded in the ciphers cipher-block-chaining mode. A partial block at the end of a file is encoded using a stream mode to avoid having to store the filesize somewhere. <p>Having larger block sizes reduces the overhead of <b>EncFS</b> a little, but it can also add overhead if your programs read small parts of files. In order to read a single byte from a file, the entire block that contains that byte must be read and decoded, so a large block size adds overhead to small requests. With write calls it is even worse, as a block must be read and decoded, the change applied and the block encoded and written back out. </p><p>The default is 512 bytes as of version 1.0. It was hard coded to 64 bytes in version 0.x, which was not as efficient as the current setting for general usage. </p>Filename Encoding<b>New in 1.1</b>. A choice is given between stream encoding of filename and block encoding. The advantage of stream encoding is that the encoded filenames will be as short as possible. If you have a filename with a single letter, it will be very short in the encoded form, where as block encoded filenames are always rounded up to the block size of the encryption cipher (8 bytes for Blowfish and 16 bytes for AES ). <p>The advantage of block encoding mode is that filename lenths all come out as a multiple of the cipher block size. This means that someone looking at your encrypted data cant tell as much about the length of your filenames. It is on by default, as it takes a similar amount of time to using the stream cipher. However stream cipher mode may be useful if you want shorter encrypted filenames for some reason. </p><p>Prior to version 1.1, only stream encoding was supported. </p>Filename Initialization Vector Chaining<b>New in 1.1</b>. In previous versions of <b>EncFS</b>, each filename element in a path was encoded separately. So if foo encoded to XXX , then it would always encode that way (given the same encryption key), no matter if the path was a/b/foo, or aa/foo/cc, etc. That meant it was possible for someone looking at the encrypted data to see if two files in different directories had the same name, even though they wouldnt know what that name decoded to. <p>With initialization vector chaining, each directory gets its own initialization vector. So a/foo and b/foo will have completely different encoded names for foo. This features has almost no performance impact (for most operations), and so is the default in all modes. </p><p><b>Note:</b> One significant performance exception is directory renames. Since the initialization vector for filename encoding depends on the directory path, any rename requires re-encoding every filename in the tree of the directory being changed. If there are thousands of files, then EncFS will have to do thousands of renames. It may also be possible that EncFS will come across a file that it cant decode or doesnt have permission to move during the rename operation, in which case it will attempt to undo any changes it made up to that point and the rename will fail. </p>Per-File Initialization Vectors<b>New in 1.1</b>. In previous versions of <b>EncFS</b>, each file was encoded in the same way. Each block in a file has always had its own initialization vector, but in a deterministic way so that block N in one file is encoded in the same was as block N in another file. That made it possible for someone to tell if two files were identical (or parts of the file were identical) by comparing the encoded data. <p>With per-file initialization vectors, each file gets its own 64bit random initialization vector, so that each file is encrypted in a different way. </p><p>This option is enabled by default. </p>External <b>New in 1.1.3</b>. This option is closely related to Per-File Initialization Vectors and Filename Initialization Vector Chaining. Basically it extends the initialization vector chaining from filenames to the per-file initialization vector. <p>When this option is enabled, the per-file initialization vector is encoded using the initialization vector derived from the filename initialization vector chaining code. This means that the data in a file becomes tied to the filename. If an encrypted file is renamed outside of encfs, it will no longer be decodable within encfs. Note that unless Block MAC headers are enabled, the decoding error will not be detected and will result in reading random looking data. </p><p>There is a cost associated with this. When External IV Chaining is enabled, hard links will not be allowed within the filesystem, as there would be no way to properly decode two different filenames pointing to the same data. </p><p>Also, renaming a file requires modifying the file header. So renames will only be allowed when the user has write access to the file. </p><p>Because of these limits, this option is disabled by default for standard mode (and enabled by default for paranoia mode). </p>Block <b>New to 1.1</b>. If this is enabled, every block in every file is stored along with a cryptographic checksum (Message Authentication Code). This makes it virtually impossible to modify a file without the change being detected by <b>EncFS</b>. <b>EncFS</b> will refuse to read data which does not pass the checksum, and will log the error and return an IO error to the application. <p>This adds substantial overhead (default being 8 bytes per filesystem block), plus computational overhead, and is not enabled by default except in paranoia mode. </p><p>When this is not enabled and if <b>EncFS</b> is asked to read modified or corrupted data, it will have no way to verify that the decoded data is what was originally encoded. </p> "},{"id": 18609,"commandid" : 2458,"title": "Attacks","page": " <br><br>The primary goal of <b>EncFS</b> is to protect data off-line. That is, provide a convenient way of storing files in a way that will frustrate any attempt to read them if the files are later intercepted.<br><br>Some algorithms in <b>EncFS</b> are also meant to frustrate on-line attacks where an attacker is assumed to be able to modify the files.<br><br>The most intrusive attacks, where an attacker has complete control of the users machine (and can therefor modify <b>EncFS</b>, or <b>FUSE</b> , or the kernel itself) are not guarded against. Do not assume that encrypted files will protect your sensitive data if you enter your password into a compromised computer. How you determine that the computer is safe to use is beyond the scope of this documentation.<br><br>That said, here are some example attacks and data gathering techniques on the filesystem contents along with the algorithms <b>EncFS</b> supports to thwart them: Attack: modifying a few bytes of an encrypted file (without knowing what they will decode to). <b>EncFS</b> does not use any form of XOR encryption which would allow single bytes to be modified without affecting others. Most modifications would affect dozens or more bytes. Additionally, MAC Block headers can be used to identify any changes to files.Attack: copying a random block of one file to a random block of another file. Each block has its own [deterministic] initialization vector.Attack: copying block N to block N of another file. When the Per-File Initialization Vector support is enabled (default in 1.1.x filesystems), a copied block will not decode properly when copied to another file.Attack: copying an entire file to another file. Can be prevented by enabling External IV Chaining mode.Attack: determine if two filenames are the same by looking at encrypted names. Filename Initialization Vector chaining prevents this by giving each file a 64-bit initialization vector derived from its full path name.Attack: compare if two files contain the same data. Per-File Initialization Vector support prevents this. "},{"id": 18610,"commandid" : 2458,"title": "Disclaimer","page": " <br><br>This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY ; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . Please refer to the COPYING file distributed with <b>EncFS</b> for complete details."},{"id": 18611,"commandid" : 2458,"title": "Authors","page": " <br><br><b>EncFS</b> was written by <b>Valient Gough &lt;<a href=mailto:vgough@pobox.com>vgough@pobox.com</a>&gt;</b>."},{"id": 18612,"commandid" : 2458,"title": "See Also","page": " <br><br><b><a href=encfsctl>encfsctl</a></b>(1) "},{"id": 18611,"commandid" : 2459,"title": "SYNOPSIS","page": "lolcat [options] [files] ..."},{"id": 18612,"commandid" : 2459,"title": "DESCRIPTION","page": "This manual page documents briefly the lolcat command.<br> lolcat is a program that concatenates files, or standard input, to standard output (like the generic cat), and adds rainbow coloring to it."},{"id": 18613,"commandid" : 2459,"title": "OPTIONS","page": "-p f, --spread=f<br> Inclination of the rainbow stripes (character widths per line hight; high values (>1000) give almost horizonal stripes, low values (0.1) almost vertical ones; default: 3.0).<br> -F f, --freq=f<br> Frequency of the rainbow (low values around 0.0001 give almost monochromous screens; default: 0.1).<br> -S i, --seed=i<br> Initial value for the random number generator; 0 means automatic (default: 0).<br> -a, --animate<br> Fade every line through an animation before printing the next one.<br> -d i, --duration=i<br> Duration of the animation (number of steps before showing next line; default: 12)<br> -s i, --speed=i<br> Speed of the animation (frame rate, ie. number of steps per second; default: 20)<br> -f, --force<br> Force color even when stdout is not a tty<br> -v, --version<br> Show version of lolcat.<br> -h, --help<br> Show summary of options."},{"id": 18614,"commandid" : 2459,"title": "EXAMPLES","page": "Typical combinations of lolcat include other programs that generate text:<br> Large colorful words can be written like this:<br> echo \"KTHXBAI\" | toilet | lolcat<br> Cows are popular, come in all colors, and tell random epigrams:<br> fortune | cowsay | lolcat -a"},{"id": 18615,"commandid" : 2459,"title": "AUTHOR","page": "lolcat was written by Moe <moe@busyloop.net>. This manual page was written by chrysn <chrysn@fsfe.org>, for the Debian project (and may be used by others)."},{"id": 18615,"commandid" : 2460,"title": "NAME","page": "airolib-ng - manage and create a WPA/WPA2 pre-computed hashes tables"} , {"id": 18616,"commandid" : 2460,"title": "SYNOPSIS","page": "airolib-ng <database> <operation> [options]"} ,{"id": 18617,"commandid" : 2460,"title": "DESCRIPTION","page": "airolib-ng is a tool for the aircrack-ng suite to store and manage essid and password lists, compute their Pairwise Master Keys (PMKs) and use them in WPA/WPA2 cracking. The program uses the lightweight SQLite3 database as the storage mechanism which is available on most platforms. The SQLite3 database was selected taking in consideration platform availability plus management, memory and disk overhead."} ,{"id": 18618,"commandid" : 2460,"title": "DATABASE","page": "database<br>It is name of the database file. Optionally specify the full path."} ,{"id": 18619,"commandid" : 2460,"title": "OPERATION","page": "--stats Output information about the database.<br> --sql <sql><br> Execute specified SQL statement.<br> --clean [all]<br> Clean the database from old junk. When specifying 'all', it will also reduce filesize if possible and run an integrity check.<br> --batch<br> Start batch-processing all combinations of ESSIDs and passwords.<br> --verify [all]<br> Verify a set of randomly chosen PMKs. If 'all' is given, all invalid PMK in the database will be deleted.<br> --import [essid|passwd] <file><br> Import a flat file as a list of ESSIDs or passwords.<br> import cowpatty <file><br> Import a coWPAtty file.<br> --export cowpatty <essid> <file><br> Export to a cowpatty file.<br>"} ,{"id": 18620,"commandid" : 2460,"title": "AUTHOR","page": "This manual page was written by Thomas d'Otreppe. Permission is granted to copy, distribute and/or modify this document under the terms of the GNU General Public License, Version 2 or any later version published by the Free Software Foundation On Debian systems, the complete text of the GNU General Public License can be found in /usr/share/common-licenses/GPL."} ,{"id": 18621,"commandid" : 2460,"title": "SEE ALSO","page": "airbase-ng(8), aircrack-ng(1), airdecap-ng(1), airdecloak-ng(1), airdriver-ng(8), aireplay-ng(8), airmon-ng(8), airodump-ng(8), airserv-ng(8), airtun-ng(8), buddy-ng(1), easside-ng(8), ivstools(1), kstats(1), makeivs-ng(1), packetforge-ng(1), tkiptun-ng(8), wesside-ng(8)"}]